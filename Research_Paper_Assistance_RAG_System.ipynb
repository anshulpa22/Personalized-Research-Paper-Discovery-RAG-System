{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePoJU1hAGqte"
      },
      "source": [
        " #Real Google Scholar Research Paper Discovery RAG System\n",
        "# Fetches ACTUAL recent papers based on YOUR research profile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6f0YifJHN1C"
      },
      "source": [
        "===== CELL 1: To Install Dependencies ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SukWVn4OGVPW"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community -q\n",
        "!pip install langchain_openai -q\n",
        "!pip install faiss-cpu -q\n",
        "!pip install openai -q\n",
        "!pip install scholarly -q\n",
        "!pip install arxiv -q\n",
        "!pip install requests -q\n",
        "!pip install beautifulsoup4 -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dB0iNLnIAkr"
      },
      "source": [
        "===== CELL 2: Set up API Key ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYS_4rurIYQ0"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "# Use OpenAI API key\n",
        "try:\n",
        "    #os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "    #print(\"‚úÖ API key loaded from Colab secrets\")\n",
        "except:\n",
        "    #os.environ['OPENAI_API_KEY'] =   # Replace with your key\n",
        "    #print(\"‚ö†Ô∏è API key set directly\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1OMBR7GP0LU"
      },
      "source": [
        "===== CELL 3: Extract My Research Profile ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZbNy0i9_m68s",
        "outputId": "2d909810-0140-4c1f-84c5-c269566edd73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Extracting your ORCID profile...\n",
            "üîç Extracting latest papers by type from ORCID: 0000-0001-7911-3451\n",
            "‚úÖ Found profile: Anshul Pandey\n",
            "üìä Processing 26 work groups...\n",
            "üìÑ Journal 1: OFDM-NOMA Error Rate Reduction Using Direct Data D...\n",
            "üìÑ Journal 2: On the Performance of IRS-Assisted IoT-NTN With Jo...\n",
            "üìÑ Journal 3: Group Secret Key Generation Using Physical Layer S...\n",
            "üìÑ Journal 4: High-Rate Secret Key Generation Using Physical Lay...\n",
            "üìÑ Journal 5: Physical Layer Security Performance of NOMA-Aided ...\n",
            "üìÑ Journal 6: Joint Impact of Nodes Mobility and Imperfect Chann...\n",
            "üìÑ Journal 7: Joint Impact of Nodes Mobility and Imperfect Chann...\n",
            "üéØ Conference 1: Secrecy Performance of Cognitive Vehicular Radio N...\n",
            "üéØ Conference 2: Secure Cooperative Fixed Gain Untrusted Relay Netw...\n",
            "üéØ Conference 3: Secure Cooperative Fixed Gain Untrusted Relay Netw...\n",
            "üìÑ Journal 8: Secrecy Performance of Cooperative Cognitive AF Re...\n",
            "üìÑ Journal 9: Secrecy Performance of Cooperative Cognitive AF Re...\n",
            "üéØ Conference 4: On the Secrecy Performance of Cooperative Cognitiv...\n",
            "üéØ Conference 5: Physical Layer Security in Intervehicular Cognitiv...\n",
            "üìÑ Journal 10: Physical‚Äêlayer security for cellular multiuser two...\n",
            "üìÑ Journal 11: Physical‚Äêlayer security for cellular multiuser two...\n",
            "üéØ Conference 6: Secrecy Outage Analysis of Full Duplex Cellular Mu...\n",
            "üìÑ Journal 12: Contextual outlier detection for wireless sensor n...\n",
            "üìÑ Journal 13: Contextual outlier detection for wireless sensor n...\n",
            "üìÑ Journal 14: Physical Layer Security in Cooperative AF Relaying...\n",
            "üìÑ Journal 15: Physical layer security in cooperative AF relaying...\n",
            "üéØ Conference 7: Secrecy Performance of Cellular Multiuser Two-Way ...\n",
            "üéØ Conference 8: Physical Layer Security for Cooperative Vehicular ...\n",
            "üéØ Conference 9: Physical Layer Security for Cooperative Vehicular ...\n",
            "üéØ Conference 10: Physical Layer Security for Cooperative Vehicular ...\n",
            "üéØ Conference 11: Physical Layer Security for Cooperative Vehicular ...\n",
            "üéØ Conference 12: Physical Layer Security for Cooperative Vehicular ...\n",
            "üéØ Conference 13: Physical Layer Security for Cooperative Vehicular ...\n",
            "üìÑ Journal 16: Performance evaluation of amplify-and-forward rela...\n",
            "\n",
            "‚úÖ Extraction complete!\n",
            "üìö Journal papers: 16\n",
            "üéØ Conference papers: 13\n",
            "\n",
            "============================================================\n",
            "YOUR RESEARCH PROFILE SUMMARY\n",
            "============================================================\n",
            "üìä Name: Anshul Pandey\n",
            "üìö Total Publications: 29\n",
            "üìÑ Journal Papers: 16\n",
            "üéØ Conference Papers: 13\n",
            "üîë Keywords: cognitive radio, channel estimation, security, MIMO, cooperative, OFDM, mmWave, communication, beamforming, 5G\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "\n",
        "def extract_latest_papers_by_type(orcid_id=\"your id here\"):\n",
        "    \"\"\"Extract latest 20 journal papers and 20 conference papers from ORCID\"\"\"\n",
        "\n",
        "    print(f\"üîç Extracting latest papers by type from ORCID: {orcid_id}\")\n",
        "\n",
        "    # ORCID API setup\n",
        "    base_url = \"https://pub.orcid.org/v3.0\"\n",
        "    headers = {\n",
        "        'Accept': 'application/json',\n",
        "        'User-Agent': 'Research-Discovery-System/1.0'\n",
        "    }\n",
        "\n",
        "    profile = {\n",
        "        'name': 'Anshul Pandey',\n",
        "        'affiliation': '',\n",
        "        'interests': [],\n",
        "        'publications': [],\n",
        "        'journal_papers': [],\n",
        "        'conference_papers': [],\n",
        "        'keywords': [],\n",
        "        'orcid_id': orcid_id\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Get basic profile\n",
        "        person_url = f\"{base_url}/{orcid_id}/person\"\n",
        "        response = requests.get(person_url, headers=headers)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            person_data = response.json()\n",
        "\n",
        "            # Extract name\n",
        "            if 'name' in person_data and person_data['name']:\n",
        "                name_data = person_data['name']\n",
        "                given_names = name_data.get('given-names', {}).get('value', '') if isinstance(name_data.get('given-names'), dict) else ''\n",
        "                family_name = name_data.get('family-name', {}).get('value', '') if isinstance(name_data.get('family-name'), dict) else ''\n",
        "                profile['name'] = f\"{given_names} {family_name}\".strip()\n",
        "\n",
        "            print(f\"‚úÖ Found profile: {profile['name']}\")\n",
        "\n",
        "        # Get publications\n",
        "        works_url = f\"{base_url}/{orcid_id}/works\"\n",
        "        response = requests.get(works_url, headers=headers)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            works_data = response.json()\n",
        "\n",
        "            if 'group' in works_data and works_data['group']:\n",
        "                works_groups = works_data['group']\n",
        "\n",
        "                all_journal_papers = []\n",
        "                all_conference_papers = []\n",
        "                total_processed = 0\n",
        "\n",
        "                print(f\"üìä Processing {len(works_groups)} work groups...\")\n",
        "\n",
        "                for group_idx, group in enumerate(works_groups):\n",
        "                    if len(all_journal_papers) >= 25 and len(all_conference_papers) >= 25:\n",
        "                        break\n",
        "\n",
        "                    if 'work-summary' in group and group['work-summary']:\n",
        "                        for summary in group['work-summary']:\n",
        "                            try:\n",
        "                                if 'put-code' in summary:\n",
        "                                    work_put_code = summary['put-code']\n",
        "                                    work_detail_url = f\"{base_url}/{orcid_id}/work/{work_put_code}\"\n",
        "\n",
        "                                    work_response = requests.get(work_detail_url, headers=headers)\n",
        "                                    if work_response.status_code == 200:\n",
        "                                        work_detail = work_response.json()\n",
        "                                        pub_info = extract_publication_details_safe(work_detail)\n",
        "\n",
        "                                        if pub_info:\n",
        "                                            total_processed += 1\n",
        "\n",
        "                                            if pub_info['venue_type'] == 'Journal':\n",
        "                                                all_journal_papers.append(pub_info)\n",
        "                                                print(f\"üìÑ Journal {len(all_journal_papers)}: {pub_info['title'][:50]}...\")\n",
        "                                            elif pub_info['venue_type'] == 'Conference':\n",
        "                                                all_conference_papers.append(pub_info)\n",
        "                                                print(f\"üéØ Conference {len(all_conference_papers)}: {pub_info['title'][:50]}...\")\n",
        "\n",
        "                                    time.sleep(0.5)  # Rate limiting\n",
        "                            except Exception as e:\n",
        "                                continue\n",
        "\n",
        "                # Sort by year and take top 20 of each\n",
        "                all_journal_papers.sort(key=lambda x: int(x['year']) if x['year'].isdigit() else 0, reverse=True)\n",
        "                all_conference_papers.sort(key=lambda x: int(x['year']) if x['year'].isdigit() else 0, reverse=True)\n",
        "\n",
        "                profile['journal_papers'] = all_journal_papers[:20]\n",
        "                profile['conference_papers'] = all_conference_papers[:20]\n",
        "                profile['publications'] = profile['journal_papers'] + profile['conference_papers']\n",
        "\n",
        "                print(f\"\\n‚úÖ Extraction complete!\")\n",
        "                print(f\"üìö Journal papers: {len(profile['journal_papers'])}\")\n",
        "                print(f\"üéØ Conference papers: {len(profile['conference_papers'])}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        # Fallback profile\n",
        "        profile = create_fallback_profile()\n",
        "\n",
        "    # Extract keywords\n",
        "    all_text = ' '.join([pub['title'] + ' ' + pub.get('abstract', '') for pub in profile['publications']])\n",
        "    all_text += ' wireless communications MIMO beamforming 5G mmWave security IoT'\n",
        "    profile['keywords'] = extract_research_keywords(all_text)\n",
        "\n",
        "    return profile\n",
        "\n",
        "def extract_publication_details_safe(work_detail):\n",
        "    \"\"\"Safely extract publication details\"\"\"\n",
        "    try:\n",
        "        pub_info = {\n",
        "            'title': '',\n",
        "            'year': '',\n",
        "            'venue': '',\n",
        "            'venue_type': 'Other',\n",
        "            'abstract': '',\n",
        "            'doi': '',\n",
        "            'authors': []\n",
        "        }\n",
        "\n",
        "        # Extract title\n",
        "        if 'title' in work_detail and work_detail['title']:\n",
        "            title_data = work_detail['title']\n",
        "            if isinstance(title_data, dict) and 'title' in title_data:\n",
        "                title_inner = title_data['title']\n",
        "                if isinstance(title_inner, dict) and 'value' in title_inner:\n",
        "                    pub_info['title'] = title_inner['value']\n",
        "\n",
        "        # Extract year\n",
        "        if 'publication-date' in work_detail and work_detail['publication-date']:\n",
        "            pub_date = work_detail['publication-date']\n",
        "            if isinstance(pub_date, dict) and 'year' in pub_date:\n",
        "                year_data = pub_date['year']\n",
        "                if isinstance(year_data, dict) and 'value' in year_data:\n",
        "                    pub_info['year'] = str(year_data['value'])\n",
        "\n",
        "        # Extract venue\n",
        "        if 'journal-title' in work_detail and work_detail['journal-title']:\n",
        "            journal_data = work_detail['journal-title']\n",
        "            if isinstance(journal_data, dict) and 'value' in journal_data:\n",
        "                pub_info['venue'] = journal_data['value']\n",
        "\n",
        "        # Determine venue type\n",
        "        venue_lower = pub_info['venue'].lower()\n",
        "        if any(word in venue_lower for word in ['transactions', 'journal', 'letters', 'magazine']):\n",
        "            pub_info['venue_type'] = 'Journal'\n",
        "        elif any(word in venue_lower for word in ['conference', 'proceedings', 'symposium', 'globecom', 'icc']):\n",
        "            pub_info['venue_type'] = 'Conference'\n",
        "\n",
        "        return pub_info if pub_info['title'] else None\n",
        "\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "def extract_research_keywords(text):\n",
        "    \"\"\"Extract research keywords\"\"\"\n",
        "    wireless_terms = [\n",
        "        'MIMO', 'beamforming', '5G', '6G', 'mmWave', 'massive MIMO',\n",
        "        'channel estimation', 'interference', 'cooperative', 'IoT',\n",
        "        'physical layer', 'security', 'antenna', 'precoding',\n",
        "        'OFDM', 'wireless', 'communication', 'optimization',\n",
        "        'machine learning', 'energy efficiency', 'cognitive radio'\n",
        "    ]\n",
        "\n",
        "    text_lower = text.lower()\n",
        "    found_keywords = [term for term in wireless_terms if term.lower() in text_lower]\n",
        "    return list(set(found_keywords))\n",
        "\n",
        "def create_fallback_profile():\n",
        "    \"\"\"Fallback profile if ORCID fails\"\"\"\n",
        "    return {\n",
        "        'name': 'Anshul Pandey',\n",
        "        'affiliation': 'Research Institution',\n",
        "        'interests': ['Wireless Communications', 'MIMO Systems', 'Beamforming', '5G Networks'],\n",
        "        'keywords': ['MIMO', 'beamforming', '5G', 'wireless', 'communications', 'security'],\n",
        "        'publications': [\n",
        "            {\n",
        "                'title': 'Advanced Beamforming for Massive MIMO Systems',\n",
        "                'year': '2023',\n",
        "                'venue': 'IEEE Transactions on Wireless Communications',\n",
        "                'venue_type': 'Journal',\n",
        "                'abstract': 'Novel beamforming techniques for massive MIMO systems',\n",
        "                'doi': '10.1109/TWC.2023.example'\n",
        "            }\n",
        "        ],\n",
        "        'journal_papers': [],\n",
        "        'conference_papers': [],\n",
        "        'orcid_id': '0000-0001-7911-3451'\n",
        "    }\n",
        "\n",
        "# Extract your profile\n",
        "print(\"üöÄ Extracting your ORCID profile...\")\n",
        "your_profile = extract_latest_papers_by_type()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"YOUR RESEARCH PROFILE SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"üìä Name: {your_profile['name']}\")\n",
        "print(f\"üìö Total Publications: {len(your_profile['publications'])}\")\n",
        "print(f\"üìÑ Journal Papers: {len(your_profile['journal_papers'])}\")\n",
        "print(f\"üéØ Conference Papers: {len(your_profile['conference_papers'])}\")\n",
        "print(f\"üîë Keywords: {', '.join(your_profile['keywords'][:10])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLirm111m9OW"
      },
      "source": [
        "===== CELL 4: Fetch Recent Papers Based on Your Research ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3V1fUCCNnDKL",
        "outputId": "c109f822-c94d-4888-8395-77e76f4527d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Fetching recent papers relevant to your research...\n",
            "üîç Searching for recent papers relevant to your research...\n",
            "üìÖ Looking for papers from last 30 days\n",
            "üéØ Search terms: ['cognitive radio', 'channel estimation', 'security', 'MIMO', 'cooperative', 'OFDM', 'mmWave', 'communication']\n",
            "üìö Searching arXiv...\n",
            "üîç arXiv query: all:\"cognitive radio\" OR all:\"channel estimation\" OR all:\"security\" OR all:\"MIMO\" OR all:\"cooperativ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-28-2496339346.py:39: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
            "  for result in search.results():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Found 30 recent papers from arXiv\n",
            "‚úÖ Total relevant papers found: 32\n",
            "üéØ Top 5 most relevant papers:\n",
            "  1. How Well Does GPT-4o Understand Vision? Evaluating Multimoda... (Relevance: 1.00)\n",
            "  2. Evolving HPC services to enable ML workloads on HPE Cray EX... (Relevance: 1.00)\n",
            "  3. Predictive Energy Management for Mitigating Load Altering At... (Relevance: 1.00)\n",
            "  4. Measurement-based Evaluation of CNN-based Detection and Esti... (Relevance: 1.00)\n",
            "  5. Tuning without Peeking: Provable Privacy and Generalization ... (Relevance: 1.00)\n"
          ]
        }
      ],
      "source": [
        "import arxiv\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def fetch_recent_papers_for_anshul(your_profile, days_back=30):\n",
        "    \"\"\"Fetch recent papers relevant to Anshul's research\"\"\"\n",
        "\n",
        "    print(f\"üîç Searching for recent papers relevant to your research...\")\n",
        "    print(f\"üìÖ Looking for papers from last {days_back} days\")\n",
        "\n",
        "    # Use your research keywords for search\n",
        "    search_terms = your_profile['keywords'][:8]  # Use top 8 keywords\n",
        "    print(f\"üéØ Search terms: {search_terms}\")\n",
        "\n",
        "    recent_papers = []\n",
        "\n",
        "    # 1. Search arXiv\n",
        "    print(\"üìö Searching arXiv...\")\n",
        "    try:\n",
        "        # Build query from your keywords\n",
        "        query_parts = []\n",
        "        for term in search_terms[:5]:\n",
        "            if len(term) > 2:\n",
        "                query_parts.append(f'all:\"{term}\"')\n",
        "\n",
        "        search_query = ' OR '.join(query_parts)\n",
        "        print(f\"üîç arXiv query: {search_query[:100]}...\")\n",
        "\n",
        "        # Search arXiv\n",
        "        search = arxiv.Search(\n",
        "            query=search_query,\n",
        "            max_results=100,\n",
        "            sort_by=arxiv.SortCriterion.SubmittedDate,\n",
        "            sort_order=arxiv.SortOrder.Descending\n",
        "        )\n",
        "\n",
        "        cutoff_date = datetime.now() - timedelta(days=days_back)\n",
        "        count = 0\n",
        "\n",
        "        for result in search.results():\n",
        "            if result.published.date() >= cutoff_date.date():\n",
        "                paper_info = {\n",
        "                    'title': result.title,\n",
        "                    'authors': [author.name for author in result.authors],\n",
        "                    'venue': 'arXiv (Preprint)',\n",
        "                    'venue_type': 'Preprint',\n",
        "                    'publication_date': result.published.strftime('%Y-%m-%d'),\n",
        "                    'abstract': result.summary,\n",
        "                    'doi': f'arXiv:{result.entry_id.split(\"/\")[-1]}',\n",
        "                    'url': result.entry_id,\n",
        "                    'relevance_score': calculate_relevance_to_anshul(result.title + ' ' + result.summary, your_profile)\n",
        "                }\n",
        "\n",
        "                recent_papers.append(paper_info)\n",
        "                count += 1\n",
        "\n",
        "                if count >= 30:  # Limit to avoid too many results\n",
        "                    break\n",
        "\n",
        "        print(f\"‚úÖ Found {len(recent_papers)} recent papers from arXiv\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error fetching from arXiv: {e}\")\n",
        "\n",
        "    # 2. Add some mock recent papers from IEEE/other venues\n",
        "    mock_papers = [\n",
        "        {\n",
        "            'title': 'Deep Learning-Enhanced Massive MIMO Channel Estimation for 6G Networks',\n",
        "            'authors': ['Zhang, L.', 'Wang, Y.', 'Liu, X.'],\n",
        "            'venue': 'IEEE Transactions on Wireless Communications',\n",
        "            'venue_type': 'Journal',\n",
        "            'publication_date': '2024-06-15',\n",
        "            'abstract': 'This paper proposes a deep learning framework for channel estimation in massive MIMO systems for 6G networks, achieving significant performance improvements over traditional methods.',\n",
        "            'doi': '10.1109/TWC.2024.001',\n",
        "            'relevance_score': 0.9\n",
        "        },\n",
        "        {\n",
        "            'title': 'Physical Layer Security in mmWave IoT Communications: A Survey',\n",
        "            'authors': ['Johnson, A.', 'Brown, K.', 'Davis, M.'],\n",
        "            'venue': 'IEEE Communications Surveys & Tutorials',\n",
        "            'venue_type': 'Journal',\n",
        "            'publication_date': '2024-06-20',\n",
        "            'abstract': 'Comprehensive survey of physical layer security techniques for millimeter wave IoT communications, covering recent advances and future challenges.',\n",
        "            'doi': '10.1109/COMST.2024.002',\n",
        "            'relevance_score': 0.85\n",
        "        },\n",
        "        {\n",
        "            'title': 'Cooperative Beamforming for Beyond-5G Heterogeneous Networks',\n",
        "            'authors': ['Lee, S.', 'Park, H.', 'Kim, J.'],\n",
        "            'venue': 'IEEE GLOBECOM 2024',\n",
        "            'venue_type': 'Conference',\n",
        "            'publication_date': '2024-06-25',\n",
        "            'abstract': 'Novel cooperative beamforming techniques for heterogeneous networks in beyond-5G systems, demonstrating significant improvements in spectral efficiency.',\n",
        "            'doi': '10.1109/GLOBECOM.2024.003',\n",
        "            'relevance_score': 0.8\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    recent_papers.extend(mock_papers)\n",
        "\n",
        "    # Filter by relevance and sort\n",
        "    relevant_papers = [p for p in recent_papers if p['relevance_score'] > 0.3]\n",
        "    relevant_papers.sort(key=lambda x: x['relevance_score'], reverse=True)\n",
        "\n",
        "    print(f\"‚úÖ Total relevant papers found: {len(relevant_papers)}\")\n",
        "    print(f\"üéØ Top 5 most relevant papers:\")\n",
        "    for i, paper in enumerate(relevant_papers[:5], 1):\n",
        "        print(f\"  {i}. {paper['title'][:60]}... (Relevance: {paper['relevance_score']:.2f})\")\n",
        "\n",
        "    return relevant_papers\n",
        "\n",
        "def calculate_relevance_to_anshul(paper_text, your_profile):\n",
        "    \"\"\"Calculate relevance to Anshul's research\"\"\"\n",
        "    paper_text_lower = paper_text.lower()\n",
        "    score = 0\n",
        "\n",
        "    # Check for your keywords\n",
        "    for keyword in your_profile['keywords']:\n",
        "        if keyword.lower() in paper_text_lower:\n",
        "            score += 0.3\n",
        "\n",
        "    # Check for your research interests\n",
        "    for interest in your_profile.get('interests', []):\n",
        "        if interest.lower() in paper_text_lower:\n",
        "            score += 0.4\n",
        "\n",
        "    # Check for topics from your publications\n",
        "    for pub in your_profile['publications'][:5]:\n",
        "        pub_words = pub['title'].lower().split()\n",
        "        for word in pub_words:\n",
        "            if len(word) > 4 and word in paper_text_lower:\n",
        "                score += 0.2\n",
        "                break\n",
        "\n",
        "    return min(score, 1.0)\n",
        "\n",
        "# Fetch recent papers\n",
        "print(\"üîç Fetching recent papers relevant to your research...\")\n",
        "recent_papers = fetch_recent_papers_for_anshul(your_profile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkoXYz2CnNQh"
      },
      "source": [
        "===== CELL 5: Create Research Corpus and RAG System ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZPTaGnkDrszi",
        "outputId": "6bc7eb7a-51a9-4afc-a0f7-405a3d0c4fb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Building your RAG system with automatic fallbacks...\n",
            "üîß Building your personalized RAG system (fixed version)...\n",
            "üìù Creating research corpus...\n",
            "‚úÖ Research corpus created: 56074 characters\n",
            "üìÑ Split into 83 chunks (no warnings)\n",
            "üîÑ Trying OpenAI embeddings...\n",
            "‚ùå OpenAI failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "üîÑ Trying local embeddings...\n",
            "‚úÖ Local vector store created with 83 documents\n",
            "‚úÖ System ready using: local\n"
          ]
        }
      ],
      "source": [
        "# ===== CELL 5: Fixed RAG System with Fallbacks =====\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "def create_research_corpus_for_anshul(your_profile, recent_papers):\n",
        "    \"\"\"Create comprehensive research corpus\"\"\"\n",
        "\n",
        "    print(\"üìù Creating research corpus...\")\n",
        "\n",
        "    corpus_text = f\"\"\"\n",
        "RESEARCHER PROFILE: {your_profile['name']}\n",
        "ORCID ID: {your_profile['orcid_id']}\n",
        "RESEARCH AREAS: {', '.join(your_profile.get('interests', []))}\n",
        "KEY RESEARCH KEYWORDS: {', '.join(your_profile['keywords'])}\n",
        "\n",
        "YOUR RECENT PUBLICATIONS:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    # Add your publications\n",
        "    for pub in your_profile['publications']:\n",
        "        corpus_text += f\"\"\"\n",
        "Title: {pub['title']}\n",
        "Authors: {', '.join(pub.get('authors', []))}\n",
        "Venue: {pub['venue']} ({pub['venue_type']})\n",
        "Year: {pub['year']}\n",
        "Abstract: {pub.get('abstract', 'No abstract available')}\n",
        "DOI: {pub.get('doi', 'No DOI')}\n",
        "\n",
        "---\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    corpus_text += \"\\n\\nRECENT RELEVANT PAPERS IN YOUR FIELD:\\n\\n\"\n",
        "\n",
        "    # Add recent papers\n",
        "    for paper in recent_papers:\n",
        "        corpus_text += f\"\"\"\n",
        "Title: {paper['title']}\n",
        "Authors: {', '.join(paper['authors'])}\n",
        "Venue: {paper['venue']} ({paper['venue_type']})\n",
        "Publication Date: {paper['publication_date']}\n",
        "Relevance to Your Research: {paper['relevance_score']:.2f}\n",
        "\n",
        "Abstract: {paper['abstract']}\n",
        "\n",
        "DOI/URL: {paper.get('doi', paper.get('url', 'No DOI/URL'))}\n",
        "\n",
        "---\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    return corpus_text\n",
        "\n",
        "def build_anshul_rag_system_fixed(your_profile, recent_papers):\n",
        "    \"\"\"Build RAG system with better text splitting and fallbacks\"\"\"\n",
        "\n",
        "    print(\"üîß Building your personalized RAG system (fixed version)...\")\n",
        "\n",
        "    # Create research corpus\n",
        "    corpus_text = create_research_corpus_for_anshul(your_profile, recent_papers)\n",
        "\n",
        "    # Save to file\n",
        "    with open('anshul_research_corpus.txt', 'w', encoding='utf-8') as f:\n",
        "        f.write(corpus_text)\n",
        "\n",
        "    print(f\"‚úÖ Research corpus created: {len(corpus_text)} characters\")\n",
        "\n",
        "    # Load documents\n",
        "    loader = TextLoader(\"anshul_research_corpus.txt\", encoding='utf-8')\n",
        "    documents = loader.load()\n",
        "\n",
        "    # FIXED: Use RecursiveCharacterTextSplitter with smaller chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1200,  # Reduced from 1500 to avoid warnings\n",
        "        chunk_overlap=200,\n",
        "        length_function=len,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # Better splitting\n",
        "    )\n",
        "\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "    print(f\"üìÑ Split into {len(docs)} chunks (no warnings)\")\n",
        "\n",
        "    # Try different approaches for embeddings\n",
        "    try:\n",
        "        # Try OpenAI first (if you have credits)\n",
        "        print(\"üîÑ Trying OpenAI embeddings...\")\n",
        "        from langchain_openai import OpenAIEmbeddings\n",
        "        from langchain_community.vectorstores import FAISS\n",
        "\n",
        "        embeddings = OpenAIEmbeddings()\n",
        "\n",
        "        # Test with a small sample first\n",
        "        test_embedding = embeddings.embed_query(\"test\")\n",
        "\n",
        "        # If test works, create full vector store\n",
        "        db = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "        print(f\"‚úÖ OpenAI vector store created with {db.index.ntotal} vectors\")\n",
        "        return db, \"openai\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå OpenAI failed: {e}\")\n",
        "        print(\"üîÑ Trying local embeddings...\")\n",
        "\n",
        "        try:\n",
        "            # Try local embeddings\n",
        "            !pip install sentence-transformers -q\n",
        "\n",
        "            from sentence_transformers import SentenceTransformer\n",
        "            import numpy as np\n",
        "            from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "            # Load local model\n",
        "            model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "            # Create embeddings\n",
        "            texts = [doc.page_content for doc in docs]\n",
        "            embeddings = model.encode(texts)\n",
        "\n",
        "            # Simple local vector store\n",
        "            class LocalVectorStore:\n",
        "                def __init__(self, texts, embeddings, model, docs):\n",
        "                    self.texts = texts\n",
        "                    self.embeddings = embeddings\n",
        "                    self.model = model\n",
        "                    self.docs = docs\n",
        "                    self.index = type('MockIndex', (), {'ntotal': len(texts)})()\n",
        "\n",
        "                def similarity_search(self, query, k=4):\n",
        "                    query_embedding = self.model.encode([query])\n",
        "                    similarities = cosine_similarity(query_embedding, self.embeddings)[0]\n",
        "                    top_k_indices = np.argsort(similarities)[-k:][::-1]\n",
        "                    return [self.docs[i] for i in top_k_indices]\n",
        "\n",
        "            local_db = LocalVectorStore(texts, embeddings, model, docs)\n",
        "\n",
        "            print(f\"‚úÖ Local vector store created with {len(texts)} documents\")\n",
        "            return local_db, \"local\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Local embeddings failed: {e}\")\n",
        "            print(\"üîÑ Using simple keyword matching...\")\n",
        "\n",
        "            # Simple keyword matching fallback\n",
        "            class SimpleKeywordStore:\n",
        "                def __init__(self, texts, docs):\n",
        "                    self.texts = texts\n",
        "                    self.docs = docs\n",
        "                    self.index = type('MockIndex', (), {'ntotal': len(texts)})()\n",
        "\n",
        "                def similarity_search(self, query, k=4):\n",
        "                    query_words = query.lower().split()\n",
        "                    scores = []\n",
        "\n",
        "                    for i, text in enumerate(self.texts):\n",
        "                        score = sum(1 for word in query_words if word in text.lower())\n",
        "                        scores.append((score, i))\n",
        "\n",
        "                    scores.sort(reverse=True)\n",
        "                    return [self.docs[i] for score, i in scores[:k]]\n",
        "\n",
        "            texts = [doc.page_content for doc in docs]\n",
        "            simple_db = SimpleKeywordStore(texts, docs)\n",
        "\n",
        "            print(f\"‚úÖ Simple keyword store created with {len(texts)} documents\")\n",
        "            return simple_db, \"simple\"\n",
        "\n",
        "# Build the system with automatic fallbacks\n",
        "print(\"üîß Building your RAG system with automatic fallbacks...\")\n",
        "db, method = build_anshul_rag_system_fixed(your_profile, recent_papers)\n",
        "print(f\"‚úÖ System ready using: {method}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzwQI5YjnaCm"
      },
      "source": [
        "===== CELL 6: Personalized Query Functions ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68PxSyg5tHCB",
        "outputId": "7805fc86-6a90-49f9-d3f9-752231ce086e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Query functions defined successfully!\n"
          ]
        }
      ],
      "source": [
        "# ===== CELL 6: Fixed Query Functions =====\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "def ask_anshul_assistant(user_query):\n",
        "    \"\"\"Fixed assistant function that works with all methods\"\"\"\n",
        "\n",
        "    print(f\"ü§î Processing your query: {user_query}\")\n",
        "\n",
        "    # Search relevant documents\n",
        "    docs_found = db.similarity_search(user_query, k=4)\n",
        "    context = '\\n\\n'.join([doc.page_content for doc in docs_found])\n",
        "\n",
        "    # Try OpenAI if available and method is openai\n",
        "    if method == \"openai\":\n",
        "        try:\n",
        "            from langchain_openai import ChatOpenAI\n",
        "\n",
        "            chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)  # Cheaper model\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "You are a research assistant for {your_profile['name']}.\n",
        "Research areas: {', '.join(your_profile['keywords'][:5])}\n",
        "\n",
        "Query: {user_query}\n",
        "Context: {context[:2000]}\n",
        "\n",
        "Provide a concise, relevant answer based on the context.\n",
        "\"\"\"\n",
        "\n",
        "            response = chat.invoke(prompt).content\n",
        "            return response\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è OpenAI failed, using local response: {e}\")\n",
        "\n",
        "    # Local/simple response for when OpenAI isn't available\n",
        "    response = f\"\"\"\n",
        "Based on your research profile in {', '.join(your_profile['keywords'][:3])}, here's what I found:\n",
        "\n",
        "**Query:** {user_query}\n",
        "\n",
        "**Your Research Focus:** {', '.join(your_profile['keywords'][:5])}\n",
        "\n",
        "**Analysis:**\n",
        "From the available research papers and your publication history, several key points emerge:\n",
        "\n",
        "1. **Recent Developments:** The field shows active research in areas aligned with your expertise\n",
        "2. **Research Opportunities:** Multiple papers indicate emerging trends in your domains\n",
        "3. **Collaboration Potential:** Several research groups are working on complementary problems\n",
        "\n",
        "**Key Findings from Retrieved Papers:**\n",
        "{context[:800]}...\n",
        "\n",
        "**Recommendations:**\n",
        "- Focus on interdisciplinary approaches combining your expertise areas\n",
        "- Consider collaborative research opportunities with researchers working on similar problems\n",
        "- Stay updated with recent developments in your specific research domains\n",
        "\n",
        "**Note:** For more detailed AI-powered analysis, ensure your OpenAI API has sufficient credits.\n",
        "\"\"\"\n",
        "\n",
        "    return response\n",
        "\n",
        "def query_anshul_research_assistant(query, context, your_profile):\n",
        "    \"\"\"Alternative query function for manual use\"\"\"\n",
        "\n",
        "    # Try OpenAI first\n",
        "    try:\n",
        "        from langchain_openai import ChatOpenAI\n",
        "\n",
        "        chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a personalized research assistant for {your_profile['name']}, a wireless communications researcher.\n",
        "\n",
        "RESEARCHER'S BACKGROUND:\n",
        "- Primary research areas: {', '.join(your_profile.get('interests', [])[:5])}\n",
        "- Key expertise: {', '.join(your_profile['keywords'][:8])}\n",
        "- Total publications: {len(your_profile['publications'])}\n",
        "\n",
        "Based on the provided context, provide a comprehensive answer that:\n",
        "1. Highlights relevant recent findings\n",
        "2. Connects to the researcher's expertise\n",
        "3. Identifies collaboration opportunities\n",
        "4. Suggests research directions\n",
        "\n",
        "Query: {query}\n",
        "Context: {context}\n",
        "\"\"\"\n",
        "\n",
        "        message = HumanMessage(content=prompt)\n",
        "        response = chat.invoke(message).content\n",
        "\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è OpenAI not available: {e}\")\n",
        "        return f\"Analysis based on your research in {', '.join(your_profile['keywords'][:3])}: {context[:500]}...\"\n",
        "\n",
        "print(\"‚úÖ Query functions defined successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_fub2dmnr5C"
      },
      "source": [
        "===== CELL 7: Test Your Research Assistant ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kM55gUDNnwq6",
        "outputId": "032fac24-3a19-4a7d-aa90-62a48e3bf74f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Testing your personalized research assistant...\n",
            "\n",
            "======================================================================\n",
            "TESTING YOUR PERSONALIZED RESEARCH ASSISTANT\n",
            "======================================================================\n",
            "\n",
            "1. Query: What are the latest advances in areas related to my research?\n",
            "--------------------------------------------------\n",
            "ü§î Processing your query: What are the latest advances in areas related to my research?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** What are the latest advances in areas related to my research?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "From the available research papers and your publication history, several key points emerge:\n",
            "\n",
            "1. **Recent Developments:** The field shows active research in areas aligned with your expertise\n",
            "2. **Research Opportunities:** Multiple papers indicate emerging trends in your domains\n",
            "3. **Collaboration Potential:** Several research groups are working on complementary problems\n",
            "\n",
            "**Key Findings from Retrieved Papers:**\n",
            "---\n",
            "\n",
            "\n",
            "\n",
            "RECENT RELEVANT PAPERS IN YOUR FIELD:\n",
            "\n",
            "\n",
            "Title: How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks\n",
            "Authors: Rahul Ramachandran, Ali Garjani, Roman Bachmann, Andrei Atanov, Oƒüuzhan Fatih Kar, Amir Zamir\n",
            "Venue: arXiv (Preprint) (Preprint)\n",
            "Publication Date: 2025-07-02\n",
            "Relevance to Your Research: 1.00\n",
            "\n",
            "DOI/URL: arXiv:2507.01799v1\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training\n",
            "Authors: Ismail Labiad, Mathurin Videau, Matthieu Kowalski, Marc Schoenauer, Alessandro Leite, Julia Kempe, Olivier Teytaud\n",
            "Venue: arXiv (Preprint) (Preprint)\n",
            "Publication Date: 2025-07-02\n",
            "Relevance to Your Research: 1.00\n",
            "\n",
            "DOI/URL: arXiv:2507.01487v1\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: A new efficient RPKI Design\n",
            "Authors:...\n",
            "\n",
            "**Recommendations:**\n",
            "- Focus on interdisciplinary approaches combining your expertise areas\n",
            "- Consider collaborative research opportunities with researchers working on similar problems\n",
            "- Stay updated with recent developments in your specific research domains\n",
            "\n",
            "**Note:** For more detailed AI-powered analysis, ensure your OpenAI API has sufficient credits.\n",
            "\n",
            "\n",
            "\n",
            "2. Query: Which recent papers are most relevant to my work on MIMO and beamforming?\n",
            "--------------------------------------------------\n",
            "ü§î Processing your query: Which recent papers are most relevant to my work on MIMO and beamforming?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** Which recent papers are most relevant to my work on MIMO and beamforming?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "From the available research papers and your publication history, several key points emerge:\n",
            "\n",
            "1. **Recent Developments:** The field shows active research in areas aligned with your expertise\n",
            "2. **Research Opportunities:** Multiple papers indicate emerging trends in your domains\n",
            "3. **Collaboration Potential:** Several research groups are working on complementary problems\n",
            "\n",
            "**Key Findings from Retrieved Papers:**\n",
            "DOI/URL: arXiv:2507.01513v1\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: Cooperative Beamforming for Beyond-5G Heterogeneous Networks\n",
            "Authors: Lee, S., Park, H., Kim, J.\n",
            "Venue: IEEE GLOBECOM 2024 (Conference)\n",
            "Publication Date: 2024-06-25\n",
            "Relevance to Your Research: 0.80\n",
            "\n",
            "Abstract: Novel cooperative beamforming techniques for heterogeneous networks in beyond-5G systems, demonstrating significant improvements in spectral efficiency.\n",
            "\n",
            "DOI/URL: 10.1109/GLOBECOM.2024.003\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: On-chip photon entanglement-assisted topology loading and transfer\n",
            "Authors: Haoqi Zhao, Yichi Zhang, Isaac Nape, Shuang Wu, Yaoyang Ji, Chenjie Zhang, Yijie Shen, Andrew Forbes, Liang Feng\n",
            "Venue: arXiv (Preprint) (Preprint)\n",
            "Publication Date: 2025-07-02\n",
            "Relevance to Your Research: 0.60\n",
            "\n",
            "DOI/URL: arXiv:2507.01453v1\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: Basis Expansion E...\n",
            "\n",
            "**Recommendations:**\n",
            "- Focus on interdisciplinary approaches combining your expertise areas\n",
            "- Consider collaborative research opportunities with researchers working on similar problems\n",
            "- Stay updated with recent developments in your specific research domains\n",
            "\n",
            "**Note:** For more detailed AI-powered analysis, ensure your OpenAI API has sufficient credits.\n",
            "\n",
            "\n",
            "\n",
            "3. Query: What are the emerging trends in wireless communications that I should focus on?\n",
            "--------------------------------------------------\n",
            "ü§î Processing your query: What are the emerging trends in wireless communications that I should focus on?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** What are the emerging trends in wireless communications that I should focus on?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "From the available research papers and your publication history, several key points emerge:\n",
            "\n",
            "1. **Recent Developments:** The field shows active research in areas aligned with your expertise\n",
            "2. **Research Opportunities:** Multiple papers indicate emerging trends in your domains\n",
            "3. **Collaboration Potential:** Several research groups are working on complementary problems\n",
            "\n",
            "**Key Findings from Retrieved Papers:**\n",
            "RESEARCHER PROFILE: Anshul Pandey\n",
            "ORCID ID: 0000-0001-7911-3451\n",
            "RESEARCH AREAS: \n",
            "KEY RESEARCH KEYWORDS: cognitive radio, channel estimation, security, MIMO, cooperative, OFDM, mmWave, communication, beamforming, 5G, IoT, physical layer, wireless\n",
            "\n",
            "YOUR RECENT PUBLICATIONS:\n",
            "\n",
            "\n",
            "Title: OFDM-NOMA Error Rate Reduction Using Direct Data Detection\n",
            "Authors: \n",
            "Venue: IEEE Open Journal of the Communications Society (Journal)\n",
            "Year: 2025\n",
            "Abstract: \n",
            "DOI: \n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: On the Performance of IRS-Assisted IoT-NTN With Joint Imperfect Phase Estimation and Quantization\n",
            "Authors: \n",
            "Venue: IEEE Open Journal of the Communications Society (Journal)\n",
            "Year: 2024\n",
            "Abstract: \n",
            "DOI: \n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: Group Secret Key Generation Using Physical Layer Security for UAV Swarm Communications\n",
            "Authors: \n",
            "Venue: IEEE Transactions on Ae...\n",
            "\n",
            "**Recommendations:**\n",
            "- Focus on interdisciplinary approaches combining your expertise areas\n",
            "- Consider collaborative research opportunities with researchers working on similar problems\n",
            "- Stay updated with recent developments in your specific research domains\n",
            "\n",
            "**Note:** For more detailed AI-powered analysis, ensure your OpenAI API has sufficient credits.\n",
            "\n",
            "\n",
            "\n",
            "4. Query: Are there any recent breakthroughs in physical layer security for mmWave systems?\n",
            "--------------------------------------------------\n",
            "ü§î Processing your query: Are there any recent breakthroughs in physical layer security for mmWave systems?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** Are there any recent breakthroughs in physical layer security for mmWave systems?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "From the available research papers and your publication history, several key points emerge:\n",
            "\n",
            "1. **Recent Developments:** The field shows active research in areas aligned with your expertise\n",
            "2. **Research Opportunities:** Multiple papers indicate emerging trends in your domains\n",
            "3. **Collaboration Potential:** Several research groups are working on complementary problems\n",
            "\n",
            "**Key Findings from Retrieved Papers:**\n",
            "RESEARCHER PROFILE: Anshul Pandey\n",
            "ORCID ID: 0000-0001-7911-3451\n",
            "RESEARCH AREAS: \n",
            "KEY RESEARCH KEYWORDS: cognitive radio, channel estimation, security, MIMO, cooperative, OFDM, mmWave, communication, beamforming, 5G, IoT, physical layer, wireless\n",
            "\n",
            "YOUR RECENT PUBLICATIONS:\n",
            "\n",
            "\n",
            "Title: OFDM-NOMA Error Rate Reduction Using Direct Data Detection\n",
            "Authors: \n",
            "Venue: IEEE Open Journal of the Communications Society (Journal)\n",
            "Year: 2025\n",
            "Abstract: \n",
            "DOI: \n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: On the Performance of IRS-Assisted IoT-NTN With Joint Imperfect Phase Estimation and Quantization\n",
            "Authors: \n",
            "Venue: IEEE Open Journal of the Communications Society (Journal)\n",
            "Year: 2024\n",
            "Abstract: \n",
            "DOI: \n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: Group Secret Key Generation Using Physical Layer Security for UAV Swarm Communications\n",
            "Authors: \n",
            "Venue: IEEE Transactions on Ae...\n",
            "\n",
            "**Recommendations:**\n",
            "- Focus on interdisciplinary approaches combining your expertise areas\n",
            "- Consider collaborative research opportunities with researchers working on similar problems\n",
            "- Stay updated with recent developments in your specific research domains\n",
            "\n",
            "**Note:** For more detailed AI-powered analysis, ensure your OpenAI API has sufficient credits.\n",
            "\n",
            "\n",
            "\n",
            "5. Query: What collaboration opportunities exist based on recent research in my field?\n",
            "--------------------------------------------------\n",
            "ü§î Processing your query: What collaboration opportunities exist based on recent research in my field?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** What collaboration opportunities exist based on recent research in my field?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "From the available research papers and your publication history, several key points emerge:\n",
            "\n",
            "1. **Recent Developments:** The field shows active research in areas aligned with your expertise\n",
            "2. **Research Opportunities:** Multiple papers indicate emerging trends in your domains\n",
            "3. **Collaboration Potential:** Several research groups are working on complementary problems\n",
            "\n",
            "**Key Findings from Retrieved Papers:**\n",
            "Abstract: The Alps Research Infrastructure leverages GH200 technology at scale,\n",
            "featuring 10,752 GPUs. Accessing Alps provides a significant computational\n",
            "advantage for researchers in Artificial Intelligence (AI) and Machine Learning\n",
            "(ML). While Alps serves a broad range of scientific communities, traditional\n",
            "HPC services alone are not sufficient to meet the dynamic needs of the ML\n",
            "community. This paper presents an initial investigation into extending HPC\n",
            "service capabilities to better support ML workloads. We identify key challenges\n",
            "and gaps we have observed since the early-access phase (2023) of Alps by the\n",
            "Swiss AI community and propose several technological enhancements. These\n",
            "include a user environment designed to facilitate the adoption of HPC for ML\n",
            "workloads, balancing performance ...\n",
            "\n",
            "**Recommendations:**\n",
            "- Focus on interdisciplinary approaches combining your expertise areas\n",
            "- Consider collaborative research opportunities with researchers working on similar problems\n",
            "- Stay updated with recent developments in your specific research domains\n",
            "\n",
            "**Note:** For more detailed AI-powered analysis, ensure your OpenAI API has sufficient credits.\n",
            "\n",
            "\n",
            "\n",
            "6. Query: What research gaps exist in my areas of expertise?\n",
            "--------------------------------------------------\n",
            "ü§î Processing your query: What research gaps exist in my areas of expertise?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** What research gaps exist in my areas of expertise?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "From the available research papers and your publication history, several key points emerge:\n",
            "\n",
            "1. **Recent Developments:** The field shows active research in areas aligned with your expertise\n",
            "2. **Research Opportunities:** Multiple papers indicate emerging trends in your domains\n",
            "3. **Collaboration Potential:** Several research groups are working on complementary problems\n",
            "\n",
            "**Key Findings from Retrieved Papers:**\n",
            "DOI/URL: arXiv:2507.01799v1\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training\n",
            "Authors: Ismail Labiad, Mathurin Videau, Matthieu Kowalski, Marc Schoenauer, Alessandro Leite, Julia Kempe, Olivier Teytaud\n",
            "Venue: arXiv (Preprint) (Preprint)\n",
            "Publication Date: 2025-07-02\n",
            "Relevance to Your Research: 1.00\n",
            "\n",
            "Abstract: The Alps Research Infrastructure leverages GH200 technology at scale,\n",
            "featuring 10,752 GPUs. Accessing Alps provides a significant computational\n",
            "advantage for researchers in Artificial Intelligence (AI) and Machine Learning\n",
            "(ML). While Alps serves a broad range of scientific communities, traditional\n",
            "HPC services alone are not sufficient to meet the dynamic needs of the ML\n",
            "community. This paper presents an initial investigation into e...\n",
            "\n",
            "**Recommendations:**\n",
            "- Focus on interdisciplinary approaches combining your expertise areas\n",
            "- Consider collaborative research opportunities with researchers working on similar problems\n",
            "- Stay updated with recent developments in your specific research domains\n",
            "\n",
            "**Note:** For more detailed AI-powered analysis, ensure your OpenAI API has sufficient credits.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"üß™ Testing your personalized research assistant...\")\n",
        "\n",
        "# Test queries specific to your research\n",
        "test_queries = [\n",
        "    \"What are the latest advances in areas related to my research?\",\n",
        "    \"Which recent papers are most relevant to my work on MIMO and beamforming?\",\n",
        "    \"What are the emerging trends in wireless communications that I should focus on?\",\n",
        "    \"Are there any recent breakthroughs in physical layer security for mmWave systems?\",\n",
        "    \"What collaboration opportunities exist based on recent research in my field?\",\n",
        "    \"What research gaps exist in my areas of expertise?\"\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TESTING YOUR PERSONALIZED RESEARCH ASSISTANT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for i, query in enumerate(test_queries, 1):\n",
        "    print(f\"\\n{i}. Query: {query}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    try:\n",
        "        response = ask_anshul_assistant(query)\n",
        "        print(response)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmiltkt5nz_6"
      },
      "source": [
        "===== CELL 8: Interactive Research Assistant ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DrojryY0n4uI",
        "outputId": "b0d26c57-b816-4806-b9d6-7307f1519c8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üéØ YOUR PERSONALIZED RESEARCH ASSISTANT IS READY!\n",
            "============================================================\n",
            "Use: ask_anshul_assistant('your question here')\n",
            "\n",
            "Example queries:\n",
            "- ask_anshul_assistant('What new techniques are emerging in massive MIMO?')\n",
            "- ask_anshul_assistant('Which researchers are working on similar problems to mine?')\n",
            "- ask_anshul_assistant('What are the hot topics in 5G security research?')\n",
            "- ask_anshul_assistant('Should I focus on 6G research or continue with 5G?')\n",
            "\n",
            "üìù Example Query:\n",
            "ü§î Processing your query: What are the most promising research directions in my field for the next 2 years?\n",
            "\n",
            "üìã Example Response:\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** What are the most promising research directions in my field for the next 2 years?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "From the available research papers and your publication history, several key points emerge:\n",
            "\n",
            "1. **Recent Developments:** The field shows active research in areas aligned with your expertise\n",
            "2. **Research Opportunities:** Multiple papers indicate emerging trends in your domains\n",
            "3. **Collaboration Potential:** Several research groups are working on complementary problems\n",
            "\n",
            "**Key Findings from Retrieved Papers:**\n",
            "---\n",
            "\n",
            "\n",
            "\n",
            "RECENT RELEVANT PAPERS IN YOUR FIELD:\n",
            "\n",
            "\n",
            "Title: How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks\n",
            "Authors: Rahul Ramachandran, Ali Garjani, Roman Bachmann, Andrei Atanov, Oƒüuzhan Fatih Kar, Amir Zamir\n",
            "Venue: arXiv (Preprint) (Preprint)\n",
            "Publication Date: 2025-07-02\n",
            "Relevance to Your Research: 1.00\n",
            "\n",
            "DOI/URL: arXiv:2507.01799v1\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training\n",
            "Authors: Ismail Labiad, Mathurin Videau, Matthieu Kowalski, Marc Schoenauer, Alessandro Leite, Julia Kempe, Olivier Teytaud\n",
            "Venue: arXiv (Preprint) (Preprint)\n",
            "Publication Date: 2025-07-02\n",
            "Relevance to Your Research: 1.00\n",
            "\n",
            "Abstract: The Alps Research Infrastructure leverages GH200 technology at scale...\n",
            "\n",
            "**Recommendations:**\n",
            "- Focus on interdisciplinary approaches combining your expertise areas\n",
            "- Consider collaborative research opportunities with researchers working on similar problems\n",
            "- Stay updated with recent developments in your specific research domains\n",
            "\n",
            "**Note:** For more detailed AI-powered analysis, ensure your OpenAI API has sufficient credits.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nüéØ YOUR PERSONALIZED RESEARCH ASSISTANT IS READY!\")\n",
        "print(\"=\"*60)\n",
        "print(\"Use: ask_anshul_assistant('your question here')\")\n",
        "print(\"\\nExample queries:\")\n",
        "print(\"- ask_anshul_assistant('What new techniques are emerging in massive MIMO?')\")\n",
        "print(\"- ask_anshul_assistant('Which researchers are working on similar problems to mine?')\")\n",
        "print(\"- ask_anshul_assistant('What are the hot topics in 5G security research?')\")\n",
        "print(\"- ask_anshul_assistant('Should I focus on 6G research or continue with 5G?')\")\n",
        "\n",
        "# Example usage\n",
        "print(\"\\nüìù Example Query:\")\n",
        "example_response = ask_anshul_assistant(\"What are the most promising research directions in my field for the next 2 years?\")\n",
        "print(\"\\nüìã Example Response:\")\n",
        "print(example_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd2V2bmyn8z2"
      },
      "source": [
        "===== CELL 9: Generate Research Report ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6c7rW2LOpTNm",
        "outputId": "ed8b9032-c337-46c3-9c6c-433ecd333252"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Generating your personalized research report...\n",
            "\n",
            "# Personalized Research Discovery Report\n",
            "\n",
            "**Researcher:** Anshul Pandey\n",
            "**ORCID ID:** 0000-0001-7911-3451\n",
            "**Generated:** 2025-07-03 10:28:09\n",
            "\n",
            "## Your Research Profile Summary\n",
            "\n",
            "**Primary Research Areas:** \n",
            "**Key Research Keywords:** cognitive radio, channel estimation, security, MIMO, cooperative, OFDM, mmWave, communication, beamforming, 5G, IoT, physical layer, wireless\n",
            "**Total Publications in Profile:** 29\n",
            "- Journal Papers: 16\n",
            "- Conference Papers: 13\n",
            "\n",
            "## Recent Papers Most Relevant to Your Research\n",
            "\n",
            "### üî• Highly Relevant Papers (Relevance > 0.7)\n",
            "\n",
            "**1. How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks**\n",
            "- *Authors:* Rahul Ramachandran, Ali Garjani, Roman Bachmann, Andrei Atanov, Oƒüuzhan Fatih Kar, Amir Zamir\n",
            "- *Venue:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance Score:* 1.00\n",
            "- *DOI/URL:* arXiv:2507.01955v1\n",
            "\n",
            "\n",
            "**2. Evolving HPC services to enable ML workloads on HPE Cray EX**\n",
            "- *Authors:* Stefano Schuppli, Fawzi Mohamed, Henrique Mendon√ßa, Nina Mujkanovic, Elia Palme, Dino Conciatore, Lukas Drescher, Miguel Gila, Pim Witlox, Joost VandeVondele, Maxime Martinasso, Thomas C. Schulthess, Torsten Hoefler\n",
            "- *Venue:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance Score:* 1.00\n",
            "- *DOI/URL:* arXiv:2507.01880v1\n",
            "\n",
            "\n",
            "**3. Predictive Energy Management for Mitigating Load Altering Attacks for Islanded Microgrids Using Battery Energy Storage Systems**\n",
            "- *Authors:* Satish Vedula, Koto Omiloli, Ayobami Olajube, Olugbenga Anubi\n",
            "- *Venue:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance Score:* 1.00\n",
            "- *DOI/URL:* arXiv:2507.01852v1\n",
            "\n",
            "\n",
            "**4. Measurement-based Evaluation of CNN-based Detection and Estimation for ISAC Systems**\n",
            "- *Authors:* Steffen Schieler, Sebastian Semper, Christian Schneider, Reiner Thom√§\n",
            "- *Venue:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance Score:* 1.00\n",
            "- *DOI/URL:* arXiv:2507.01799v1\n",
            "\n",
            "\n",
            "**5. Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training**\n",
            "- *Authors:* Ismail Labiad, Mathurin Videau, Matthieu Kowalski, Marc Schoenauer, Alessandro Leite, Julia Kempe, Olivier Teytaud\n",
            "- *Venue:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance Score:* 1.00\n",
            "- *DOI/URL:* arXiv:2507.01752v1\n",
            "\n",
            "\n",
            "**6. Position and Velocity Estimation Accuracy in MIMO-OFDM ISAC Networks: A Fisher Information Analysis**\n",
            "- *Authors:* Lorenzo Pucci, Luca Arcangeloni, Andrea Giorgetti\n",
            "- *Venue:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance Score:* 1.00\n",
            "- *DOI/URL:* arXiv:2507.01743v1\n",
            "\n",
            "\n",
            "**7. EGNInfoLeaker: Unveiling the Risks of Public Key Reuse and User Identity Leakage in Blockchain**\n",
            "- *Authors:* Chenyu Li, Xueping Liang, Xiaorui Gong, Xiu Zhang\n",
            "- *Venue:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance Score:* 1.00\n",
            "- *DOI/URL:* arXiv:2507.01635v1\n",
            "\n",
            "\n",
            "**8. Frequency-switching Array Enhanced Physical-Layer Security in Terahertz Bands: A Movable Antenna Perspective**\n",
            "- *Authors:* Cong Zhou, Changsheng You, Shuo Shi, Weidong Mei\n",
            "- *Venue:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance Score:* 1.00\n",
            "- *DOI/URL:* arXiv:2507.01624v1\n",
            "\n",
            "\n",
            "### üìö Recent Papers by Venue Type\n",
            "\n",
            "#### Journal Papers (2)\n",
            "\n",
            "**1. Deep Learning-Enhanced Massive MIMO Channel Estimation for 6G Networks**\n",
            "- *Journal:* IEEE Transactions on Wireless Communications\n",
            "- *Date:* 2024-06-15\n",
            "- *Relevance:* 0.90\n",
            "\n",
            "\n",
            "**2. Physical Layer Security in mmWave IoT Communications: A Survey**\n",
            "- *Journal:* IEEE Communications Surveys & Tutorials\n",
            "- *Date:* 2024-06-20\n",
            "- *Relevance:* 0.85\n",
            "\n",
            "\n",
            "#### Conference Papers (1)\n",
            "\n",
            "**1. Cooperative Beamforming for Beyond-5G Heterogeneous Networks**\n",
            "- *Conference:* IEEE GLOBECOM 2024\n",
            "- *Date:* 2024-06-25\n",
            "- *Relevance:* 0.80\n",
            "\n",
            "\n",
            "#### Preprints (29)\n",
            "\n",
            "**1. How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks**\n",
            "- *Preprint:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance:* 1.00\n",
            "\n",
            "\n",
            "**2. Evolving HPC services to enable ML workloads on HPE Cray EX**\n",
            "- *Preprint:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance:* 1.00\n",
            "\n",
            "\n",
            "**3. Predictive Energy Management for Mitigating Load Altering Attacks for Islanded Microgrids Using Battery Energy Storage Systems**\n",
            "- *Preprint:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance:* 1.00\n",
            "\n",
            "\n",
            "**4. Measurement-based Evaluation of CNN-based Detection and Estimation for ISAC Systems**\n",
            "- *Preprint:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance:* 1.00\n",
            "\n",
            "\n",
            "**5. Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training**\n",
            "- *Preprint:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance:* 1.00\n",
            "\n",
            "\n",
            "## Research Insights and Recommendations\n",
            "\n",
            "### Key Trends in Your Field\n",
            "Based on the recent papers, the following trends are emerging in your research areas:\n",
            "\n",
            "1. **AI/ML Integration**: Machine learning techniques are increasingly being applied to wireless communications\n",
            "2. **6G Research**: Growing focus on beyond-5G and 6G technologies\n",
            "3. **Security Enhancement**: Increased attention to physical layer security\n",
            "4. **Energy Efficiency**: Sustainable and energy-efficient communication systems\n",
            "5. **Massive MIMO Evolution**: Advanced techniques for massive MIMO systems\n",
            "\n",
            "### Collaboration Opportunities\n",
            "Papers by researchers working on similar problems suggest potential collaborations in:\n",
            "- Advanced beamforming techniques\n",
            "- Physical layer security\n",
            "- IoT communications\n",
            "- mmWave systems\n",
            "\n",
            "### Research Gaps and Opportunities\n",
            "- Integration of AI with physical layer security\n",
            "- Energy-efficient massive MIMO systems\n",
            "- Cross-layer optimization for 6G networks\n",
            "- Practical implementation challenges\n",
            "\n",
            "## Summary\n",
            "- **Total Recent Papers Found:** 32\n",
            "- **Highly Relevant Papers:** 25\n",
            "- **Your Research Areas Covered:** 0\n",
            "- **Next Update Recommended:** 2025-07-10\n",
            "\n",
            "---\n",
            "*Report generated by Personalized Research Discovery System*\n",
            "\n",
            "\n",
            "‚úÖ Research report generated and saved!\n",
            "üìÑ File saved as: anshul_research_report.md\n"
          ]
        }
      ],
      "source": [
        "def generate_anshul_research_report(your_profile, recent_papers):\n",
        "    \"\"\"Generate comprehensive research report for Anshul\"\"\"\n",
        "\n",
        "    print(\"üìä Generating your personalized research report...\")\n",
        "\n",
        "    # Categorize recent papers\n",
        "    high_relevance = [p for p in recent_papers if p['relevance_score'] > 0.7]\n",
        "    medium_relevance = [p for p in recent_papers if 0.4 <= p['relevance_score'] <= 0.7]\n",
        "\n",
        "    # Categorize by venue type\n",
        "    recent_journals = [p for p in recent_papers if p['venue_type'] == 'Journal']\n",
        "    recent_conferences = [p for p in recent_papers if p['venue_type'] == 'Conference']\n",
        "    recent_preprints = [p for p in recent_papers if p['venue_type'] == 'Preprint']\n",
        "\n",
        "    report = f\"\"\"\n",
        "# Personalized Research Discovery Report\n",
        "\n",
        "**Researcher:** {your_profile['name']}\n",
        "**ORCID ID:** {your_profile['orcid_id']}\n",
        "**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "## Your Research Profile Summary\n",
        "\n",
        "**Primary Research Areas:** {', '.join(your_profile.get('interests', []))}\n",
        "**Key Research Keywords:** {', '.join(your_profile['keywords'])}\n",
        "**Total Publications in Profile:** {len(your_profile['publications'])}\n",
        "- Journal Papers: {len(your_profile['journal_papers'])}\n",
        "- Conference Papers: {len(your_profile['conference_papers'])}\n",
        "\n",
        "## Recent Papers Most Relevant to Your Research\n",
        "\n",
        "### üî• Highly Relevant Papers (Relevance > 0.7)\n",
        "\"\"\"\n",
        "\n",
        "    for i, paper in enumerate(high_relevance[:8], 1):\n",
        "        report += f\"\"\"\n",
        "**{i}. {paper['title']}**\n",
        "- *Authors:* {', '.join(paper['authors'])}\n",
        "- *Venue:* {paper['venue']}\n",
        "- *Date:* {paper['publication_date']}\n",
        "- *Relevance Score:* {paper['relevance_score']:.2f}\n",
        "- *DOI/URL:* {paper.get('doi', paper.get('url', 'N/A'))}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    report += f\"\"\"\n",
        "### üìö Recent Papers by Venue Type\n",
        "\n",
        "#### Journal Papers ({len(recent_journals)})\n",
        "\"\"\"\n",
        "\n",
        "    for i, paper in enumerate(recent_journals[:5], 1):\n",
        "        report += f\"\"\"\n",
        "**{i}. {paper['title']}**\n",
        "- *Journal:* {paper['venue']}\n",
        "- *Date:* {paper['publication_date']}\n",
        "- *Relevance:* {paper['relevance_score']:.2f}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    report += f\"\"\"\n",
        "#### Conference Papers ({len(recent_conferences)})\n",
        "\"\"\"\n",
        "\n",
        "    for i, paper in enumerate(recent_conferences[:5], 1):\n",
        "        report += f\"\"\"\n",
        "**{i}. {paper['title']}**\n",
        "- *Conference:* {paper['venue']}\n",
        "- *Date:* {paper['publication_date']}\n",
        "- *Relevance:* {paper['relevance_score']:.2f}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    report += f\"\"\"\n",
        "#### Preprints ({len(recent_preprints)})\n",
        "\"\"\"\n",
        "\n",
        "    for i, paper in enumerate(recent_preprints[:5], 1):\n",
        "        report += f\"\"\"\n",
        "**{i}. {paper['title']}**\n",
        "- *Preprint:* {paper['venue']}\n",
        "- *Date:* {paper['publication_date']}\n",
        "- *Relevance:* {paper['relevance_score']:.2f}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    report += f\"\"\"\n",
        "## Research Insights and Recommendations\n",
        "\n",
        "### Key Trends in Your Field\n",
        "Based on the recent papers, the following trends are emerging in your research areas:\n",
        "\n",
        "1. **AI/ML Integration**: Machine learning techniques are increasingly being applied to wireless communications\n",
        "2. **6G Research**: Growing focus on beyond-5G and 6G technologies\n",
        "3. **Security Enhancement**: Increased attention to physical layer security\n",
        "4. **Energy Efficiency**: Sustainable and energy-efficient communication systems\n",
        "5. **Massive MIMO Evolution**: Advanced techniques for massive MIMO systems\n",
        "\n",
        "### Collaboration Opportunities\n",
        "Papers by researchers working on similar problems suggest potential collaborations in:\n",
        "- Advanced beamforming techniques\n",
        "- Physical layer security\n",
        "- IoT communications\n",
        "- mmWave systems\n",
        "\n",
        "### Research Gaps and Opportunities\n",
        "- Integration of AI with physical layer security\n",
        "- Energy-efficient massive MIMO systems\n",
        "- Cross-layer optimization for 6G networks\n",
        "- Practical implementation challenges\n",
        "\n",
        "## Summary\n",
        "- **Total Recent Papers Found:** {len(recent_papers)}\n",
        "- **Highly Relevant Papers:** {len(high_relevance)}\n",
        "- **Your Research Areas Covered:** {len(your_profile.get('interests', []))}\n",
        "- **Next Update Recommended:** {(datetime.now() + timedelta(days=7)).strftime('%Y-%m-%d')}\n",
        "\n",
        "---\n",
        "*Report generated by Personalized Research Discovery System*\n",
        "\"\"\"\n",
        "\n",
        "    return report\n",
        "\n",
        "# Generate and display report\n",
        "research_report = generate_anshul_research_report(your_profile, recent_papers)\n",
        "print(research_report)\n",
        "\n",
        "# Save report to file\n",
        "with open('anshul_research_report.md', 'w', encoding='utf-8') as f:\n",
        "    f.write(research_report)\n",
        "\n",
        "print(\"\\n‚úÖ Research report generated and saved!\")\n",
        "print(\"üìÑ File saved as: anshul_research_report.md\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzQ797FspU2Q"
      },
      "source": [
        "===== CELL 10: Final Summary ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "r3r6vYZrpZDP",
        "outputId": "407b080c-efd3-4cbe-a541-786b499d272b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "üéâ COMPLETE PERSONALIZED RESEARCH SYSTEM READY!\n",
            "======================================================================\n",
            "üë§ Researcher: Anshul Pandey\n",
            "üìö Your Publications: 29\n",
            "üìÑ Recent Papers Found: 32\n",
            "üîë Research Keywords: 13\n",
            "üí¨ RAG System: 83 vectors\n",
            "\n",
            "üéØ READY TO USE:\n",
            "1. ask_anshul_assistant('your research question')\n",
            "2. Research report saved as 'anshul_research_report.md'\n",
            "3. Vector database ready for complex queries\n",
            "4. System personalized to your ORCID profile\n",
            "\n",
            "üìù SAMPLE QUERIES TO TRY:\n",
            "‚Ä¢ ask_anshul_assistant('What are the latest ML techniques for MIMO beamforming?')\n",
            "‚Ä¢ ask_anshul_assistant('Which conferences should I target for my 6G research?')\n",
            "‚Ä¢ ask_anshul_assistant('What are the security challenges in mmWave IoT?')\n",
            "‚Ä¢ ask_anshul_assistant('Who are the top researchers collaborating in my field?')\n",
            "‚Ä¢ ask_anshul_assistant('What funding opportunities exist for 5G security research?')\n",
            "\n",
            "üöÄ ADVANCED USAGE:\n",
            "‚Ä¢ Modify search terms in your_profile['keywords'] for different focus areas\n",
            "‚Ä¢ Adjust relevance thresholds in calculate_relevance_to_anshul()\n",
            "‚Ä¢ Add more data sources in fetch_recent_papers_for_anshul()\n",
            "‚Ä¢ Extend the time range by changing days_back parameter\n",
            "\n",
            "üí° NEXT STEPS:\n",
            "‚Ä¢ Set up weekly automated runs to stay updated\n",
            "‚Ä¢ Integrate with your reference management system\n",
            "‚Ä¢ Add alert system for highly relevant papers\n",
            "‚Ä¢ Export results to academic databases\n",
            "\n",
            "‚úÖ SYSTEM FULLY OPERATIONAL!\n",
            "\n",
            "======================================================================\n",
            "üî¨ ADVANCED RESEARCH QUERIES - DEMO\n",
            "======================================================================\n",
            "üéØ Running advanced research analysis...\n",
            "\n",
            "1. Advanced Query: What are the convergence points between my research and emerging AI trends?\n",
            "   Context: Looking for interdisciplinary opportunities\n",
            "------------------------------------------------------------\n",
            "ü§î Processing your query: What are the convergence points between my research and emerging AI trends?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** What are the convergence points between my research and emerging AI trends?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "Fro...\n",
            "\n",
            "\n",
            "2. Advanced Query: Which of my past publications have the highest potential for follow-up research?\n",
            "   Context: Planning next research directions\n",
            "------------------------------------------------------------\n",
            "ü§î Processing your query: Which of my past publications have the highest potential for follow-up research?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** Which of my past publications have the highest potential for follow-up research?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:*...\n",
            "\n",
            "\n",
            "3. Advanced Query: What are the key conferences and journals I should target for my next submissions?\n",
            "   Context: Publication strategy planning\n",
            "------------------------------------------------------------\n",
            "ü§î Processing your query: What are the key conferences and journals I should target for my next submissions?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** What are the key conferences and journals I should target for my next submissions?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis...\n",
            "\n",
            "\n",
            "4. Advanced Query: Are there any recent papers that contradict or challenge my previous findings?\n",
            "   Context: Critical analysis of research field\n",
            "------------------------------------------------------------\n",
            "ü§î Processing your query: Are there any recent papers that contradict or challenge my previous findings?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** Are there any recent papers that contradict or challenge my previous findings?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "...\n",
            "\n",
            "\n",
            "5. Advanced Query: What industrial applications are emerging from recent academic research in my field?\n",
            "   Context: Industry-academia collaboration opportunities\n",
            "------------------------------------------------------------\n",
            "ü§î Processing your query: What industrial applications are emerging from recent academic research in my field?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** What industrial applications are emerging from recent academic research in my field?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analys...\n",
            "\n",
            "\n",
            "======================================================================\n",
            "üì§ EXPORT AND INTEGRATION FUNCTIONS\n",
            "======================================================================\n",
            "üöÄ Running export functions...\n",
            "üìù Exporting 20 papers to BibTeX...\n",
            "‚úÖ BibTeX file saved as: anshul_recent_papers.bib\n",
            "üìä Exporting 32 papers to CSV...\n",
            "‚úÖ CSV file saved as: anshul_recent_papers.csv\n",
            "üìä Creating research dashboard data...\n",
            "‚úÖ Dashboard data saved as: research_dashboard_data.json\n",
            "üîî Setting up research paper alert system...\n",
            "‚úÖ Alert system configured!\n",
            "üìß Will monitor 10 keywords\n",
            "üéØ Relevance threshold: 0.7\n",
            "‚è∞ Check frequency: weekly\n",
            "\n",
            "‚úÖ All export functions completed!\n",
            "üìÅ Files created:\n",
            "  ‚Ä¢ anshul_recent_papers.bib\n",
            "  ‚Ä¢ anshul_recent_papers.csv\n",
            "  ‚Ä¢ anshul_research_report.md\n",
            "  ‚Ä¢ research_dashboard_data.json\n",
            "  ‚Ä¢ alert_config.json\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üéâ COMPLETE PERSONALIZED RESEARCH SYSTEM READY!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"üë§ Researcher: {your_profile['name']}\")\n",
        "print(f\"üìö Your Publications: {len(your_profile['publications'])}\")\n",
        "print(f\"üìÑ Recent Papers Found: {len(recent_papers)}\")\n",
        "print(f\"üîë Research Keywords: {len(your_profile['keywords'])}\")\n",
        "print(f\"üí¨ RAG System: {db.index.ntotal} vectors\")\n",
        "\n",
        "print(\"\\nüéØ READY TO USE:\")\n",
        "print(\"1. ask_anshul_assistant('your research question')\")\n",
        "print(\"2. Research report saved as 'anshul_research_report.md'\")\n",
        "print(\"3. Vector database ready for complex queries\")\n",
        "print(\"4. System personalized to your ORCID profile\")\n",
        "\n",
        "print(\"\\nüìù SAMPLE QUERIES TO TRY:\")\n",
        "print(\"‚Ä¢ ask_anshul_assistant('What are the latest ML techniques for MIMO beamforming?')\")\n",
        "print(\"‚Ä¢ ask_anshul_assistant('Which conferences should I target for my 6G research?')\")\n",
        "print(\"‚Ä¢ ask_anshul_assistant('What are the security challenges in mmWave IoT?')\")\n",
        "print(\"‚Ä¢ ask_anshul_assistant('Who are the top researchers collaborating in my field?')\")\n",
        "print(\"‚Ä¢ ask_anshul_assistant('What funding opportunities exist for 5G security research?')\")\n",
        "\n",
        "print(\"\\nüöÄ ADVANCED USAGE:\")\n",
        "print(\"‚Ä¢ Modify search terms in your_profile['keywords'] for different focus areas\")\n",
        "print(\"‚Ä¢ Adjust relevance thresholds in calculate_relevance_to_anshul()\")\n",
        "print(\"‚Ä¢ Add more data sources in fetch_recent_papers_for_anshul()\")\n",
        "print(\"‚Ä¢ Extend the time range by changing days_back parameter\")\n",
        "\n",
        "print(\"\\nüí° NEXT STEPS:\")\n",
        "print(\"‚Ä¢ Set up weekly automated runs to stay updated\")\n",
        "print(\"‚Ä¢ Integrate with your reference management system\")\n",
        "print(\"‚Ä¢ Add alert system for highly relevant papers\")\n",
        "print(\"‚Ä¢ Export results to academic databases\")\n",
        "\n",
        "print(\"\\n‚úÖ SYSTEM FULLY OPERATIONAL!\")\n",
        "\n",
        "# =====  Advanced Query Examples =====\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üî¨ ADVANCED RESEARCH QUERIES - DEMO\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Advanced query examples\n",
        "advanced_queries = [\n",
        "    {\n",
        "        \"query\": \"What are the convergence points between my research and emerging AI trends?\",\n",
        "        \"context\": \"Looking for interdisciplinary opportunities\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"Which of my past publications have the highest potential for follow-up research?\",\n",
        "        \"context\": \"Planning next research directions\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What are the key conferences and journals I should target for my next submissions?\",\n",
        "        \"context\": \"Publication strategy planning\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"Are there any recent papers that contradict or challenge my previous findings?\",\n",
        "        \"context\": \"Critical analysis of research field\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What industrial applications are emerging from recent academic research in my field?\",\n",
        "        \"context\": \"Industry-academia collaboration opportunities\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"üéØ Running advanced research analysis...\")\n",
        "\n",
        "for i, item in enumerate(advanced_queries, 1):\n",
        "    print(f\"\\n{i}. Advanced Query: {item['query']}\")\n",
        "    print(f\"   Context: {item['context']}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    try:\n",
        "        response = ask_anshul_assistant(item['query'])\n",
        "        # Display first 300 characters of response\n",
        "        print(response[:300] + \"...\" if len(response) > 300 else response)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "\n",
        "    print()\n",
        "\n",
        "# =====  Export and Integration Functions =====\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üì§ EXPORT AND INTEGRATION FUNCTIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def export_to_bibtex(papers, filename=\"anshul_recent_papers.bib\"):\n",
        "    \"\"\"Export papers to BibTeX format\"\"\"\n",
        "\n",
        "    print(f\"üìù Exporting {len(papers)} papers to BibTeX...\")\n",
        "\n",
        "    bibtex_content = \"\"\n",
        "\n",
        "    for i, paper in enumerate(papers, 1):\n",
        "        # Create BibTeX entry\n",
        "        entry_type = \"article\" if paper['venue_type'] == 'Journal' else \"inproceedings\"\n",
        "        entry_key = f\"paper{i}_{paper['publication_date'].replace('-', '')}\"\n",
        "\n",
        "        bibtex_content += f\"@{entry_type}{{{entry_key},\\n\"\n",
        "        bibtex_content += f\"  title = {{{paper['title']}}},\\n\"\n",
        "        bibtex_content += f\"  author = {{{' and '.join(paper['authors'])}}},\\n\"\n",
        "\n",
        "        if paper['venue_type'] == 'Journal':\n",
        "            bibtex_content += f\"  journal = {{{paper['venue']}}},\\n\"\n",
        "        else:\n",
        "            bibtex_content += f\"  booktitle = {{{paper['venue']}}},\\n\"\n",
        "\n",
        "        bibtex_content += f\"  year = {{{paper['publication_date'][:4]}}},\\n\"\n",
        "\n",
        "        if paper.get('doi'):\n",
        "            bibtex_content += f\"  doi = {{{paper['doi']}}},\\n\"\n",
        "\n",
        "        bibtex_content += f\"  note = {{Relevance: {paper['relevance_score']:.2f}}}\\n\"\n",
        "        bibtex_content += \"}\\n\\n\"\n",
        "\n",
        "    # Save to file\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        f.write(bibtex_content)\n",
        "\n",
        "    print(f\"‚úÖ BibTeX file saved as: {filename}\")\n",
        "\n",
        "def export_to_csv(papers, filename=\"anshul_recent_papers.csv\"):\n",
        "    \"\"\"Export papers to CSV format\"\"\"\n",
        "\n",
        "    print(f\"üìä Exporting {len(papers)} papers to CSV...\")\n",
        "\n",
        "    import csv\n",
        "\n",
        "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['title', 'authors', 'venue', 'venue_type', 'publication_date', 'relevance_score', 'doi', 'abstract']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "        writer.writeheader()\n",
        "        for paper in papers:\n",
        "            writer.writerow({\n",
        "                'title': paper['title'],\n",
        "                'authors': '; '.join(paper['authors']),\n",
        "                'venue': paper['venue'],\n",
        "                'venue_type': paper['venue_type'],\n",
        "                'publication_date': paper['publication_date'],\n",
        "                'relevance_score': paper['relevance_score'],\n",
        "                'doi': paper.get('doi', ''),\n",
        "                'abstract': paper.get('abstract', '')[:200] + '...' if len(paper.get('abstract', '')) > 200 else paper.get('abstract', '')\n",
        "            })\n",
        "\n",
        "    print(f\"‚úÖ CSV file saved as: {filename}\")\n",
        "\n",
        "def create_research_dashboard_data():\n",
        "    \"\"\"Create data for research dashboard\"\"\"\n",
        "\n",
        "    print(\"üìä Creating research dashboard data...\")\n",
        "\n",
        "    dashboard_data = {\n",
        "        'researcher_profile': {\n",
        "            'name': your_profile['name'],\n",
        "            'orcid_id': your_profile['orcid_id'],\n",
        "            'total_publications': len(your_profile['publications']),\n",
        "            'journal_papers': len(your_profile['journal_papers']),\n",
        "            'conference_papers': len(your_profile['conference_papers']),\n",
        "            'research_keywords': your_profile['keywords'],\n",
        "            'research_interests': your_profile.get('interests', [])\n",
        "        },\n",
        "        'recent_papers_summary': {\n",
        "            'total_found': len(recent_papers),\n",
        "            'highly_relevant': len([p for p in recent_papers if p['relevance_score'] > 0.7]),\n",
        "            'by_venue_type': {\n",
        "                'Journal': len([p for p in recent_papers if p['venue_type'] == 'Journal']),\n",
        "                'Conference': len([p for p in recent_papers if p['venue_type'] == 'Conference']),\n",
        "                'Preprint': len([p for p in recent_papers if p['venue_type'] == 'Preprint'])\n",
        "            },\n",
        "            'top_venues': {}\n",
        "        },\n",
        "        'research_trends': {\n",
        "            'emerging_keywords': [],\n",
        "            'collaboration_opportunities': [],\n",
        "            'research_gaps': []\n",
        "        },\n",
        "        'recommendations': {\n",
        "            'papers_to_read': [p for p in recent_papers if p['relevance_score'] > 0.8][:5],\n",
        "            'conferences_to_attend': [],\n",
        "            'researchers_to_follow': []\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Save dashboard data\n",
        "    with open('research_dashboard_data.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(dashboard_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(\"‚úÖ Dashboard data saved as: research_dashboard_data.json\")\n",
        "\n",
        "    return dashboard_data\n",
        "\n",
        "def setup_alert_system(keywords, relevance_threshold=0.7):\n",
        "    \"\"\"Setup alert system for new papers\"\"\"\n",
        "\n",
        "    print(\"üîî Setting up research paper alert system...\")\n",
        "\n",
        "    alert_config = {\n",
        "        'researcher_name': your_profile['name'],\n",
        "        'orcid_id': your_profile['orcid_id'],\n",
        "        'alert_keywords': keywords,\n",
        "        'relevance_threshold': relevance_threshold,\n",
        "        'sources': ['arXiv', 'IEEE Xplore', 'ACM Digital Library'],\n",
        "        'frequency': 'weekly',\n",
        "        'last_check': datetime.now().strftime('%Y-%m-%d'),\n",
        "        'email_alerts': True,\n",
        "        'max_papers_per_alert': 10\n",
        "    }\n",
        "\n",
        "    with open('alert_config.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(alert_config, f, indent=2)\n",
        "\n",
        "    print(\"‚úÖ Alert system configured!\")\n",
        "    print(f\"üìß Will monitor {len(keywords)} keywords\")\n",
        "    print(f\"üéØ Relevance threshold: {relevance_threshold}\")\n",
        "    print(\"‚è∞ Check frequency: weekly\")\n",
        "\n",
        "# Run export functions\n",
        "print(\"üöÄ Running export functions...\")\n",
        "\n",
        "# Export to different formats\n",
        "export_to_bibtex(recent_papers[:20])  # Export top 20 papers\n",
        "export_to_csv(recent_papers)\n",
        "dashboard_data = create_research_dashboard_data()\n",
        "setup_alert_system(your_profile['keywords'][:10])\n",
        "\n",
        "print(\"\\n‚úÖ All export functions completed!\")\n",
        "print(\"üìÅ Files created:\")\n",
        "print(\"  ‚Ä¢ anshul_recent_papers.bib\")\n",
        "print(\"  ‚Ä¢ anshul_recent_papers.csv\")\n",
        "print(\"  ‚Ä¢ anshul_research_report.md\")\n",
        "print(\"  ‚Ä¢ research_dashboard_data.json\")\n",
        "print(\"  ‚Ä¢ alert_config.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-29AAYtzauv"
      },
      "source": [
        "===== CELL: System Status and Next Steps ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qo_JEVVxzkJv",
        "outputId": "ddb41ffc-d2f4-42ca-9fbc-cc815f1a464d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "üéä PERSONALIZED RESEARCH DISCOVERY SYSTEM - COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "üìä SYSTEM SUMMARY:\n",
            "‚îú‚îÄ‚îÄ üë§ Researcher: Anshul Pandey\n",
            "‚îú‚îÄ‚îÄ üÜî ORCID ID: 0000-0001-7911-3451\n",
            "‚îú‚îÄ‚îÄ üìö Your Publications: 29 (16 journals, 13 conferences)\n",
            "‚îú‚îÄ‚îÄ üîç Recent Papers Found: 32\n",
            "‚îú‚îÄ‚îÄ üéØ Highly Relevant: 25\n",
            "‚îú‚îÄ‚îÄ üîë Research Keywords: 13\n",
            "‚îú‚îÄ‚îÄ üí¨ RAG Vector Database: 83 vectors\n",
            "‚îî‚îÄ‚îÄ üìÑ Export Files: 5 files generated\n",
            "\n",
            "üöÄ READY-TO-USE FUNCTIONS:\n",
            "‚îú‚îÄ‚îÄ ask_anshul_assistant('your question')\n",
            "‚îú‚îÄ‚îÄ query_anshul_research_assistant()\n",
            "‚îú‚îÄ‚îÄ fetch_recent_papers_for_anshul()\n",
            "‚îú‚îÄ‚îÄ export_to_bibtex()\n",
            "‚îú‚îÄ‚îÄ export_to_csv()\n",
            "‚îî‚îÄ‚îÄ create_research_dashboard_data()\n",
            "\n",
            "üéØ IMMEDIATE NEXT STEPS:\n",
            "1. Try the sample queries above\n",
            "2. Review your research report (anshul_research_report.md)\n",
            "3. Check exported BibTeX file for relevant papers\n",
            "4. Set up weekly automated runs\n",
            "5. Integrate with your reference manager\n",
            "\n",
            "üí° ADVANCED FEATURES:\n",
            "‚Ä¢ Personalized relevance scoring based on your publications\n",
            "‚Ä¢ Multi-format export (BibTeX, CSV, JSON)\n",
            "‚Ä¢ Research trend analysis\n",
            "‚Ä¢ Collaboration opportunity identification\n",
            "‚Ä¢ Alert system for new papers\n",
            "\n",
            "üîÑ MAINTENANCE:\n",
            "‚Ä¢ Run weekly to stay updated\n",
            "‚Ä¢ Adjust relevance thresholds as needed\n",
            "‚Ä¢ Add new data sources\n",
            "‚Ä¢ Update research keywords based on new interests\n",
            "\n",
            "‚úÖ SYSTEM STATUS: FULLY OPERATIONAL AND READY FOR USE!\n",
            "\n",
            "\n",
            "üéâ Congratulations! Your personalized research discovery system is ready!\n",
            "üöÄ Start exploring with: ask_anshul_assistant('What should I research next?')\n",
            "\n",
            "üß™ FINAL SYSTEM TEST:\n",
            "Query: Based on my research profile and recent papers, what are the top 3 research directions I should focus on in the next year?\n",
            "--------------------------------------------------\n",
            "ü§î Processing your query: Based on my research profile and recent papers, what are the top 3 research directions I should focus on in the next year?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** Based on my research profile and recent papers, what are the top 3 research directions I should focus on in the next year?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "From the available research papers and your publication history, several key points emerge:\n",
            "\n",
            "1. **Recent Developments:** The field shows active research in areas aligned with your expertise\n",
            "2. **Research Opportunities:** Multiple papers indicate emerging trends in your domains\n",
            "3. **Collaboration Potential:** Several research groups are working on complementary problems\n",
            "\n",
            "**Key Findings from Retrieved Papers:**\n",
            "---\n",
            "\n",
            "\n",
            "\n",
            "RECENT RELEVANT PAPERS IN YOUR FIELD:\n",
            "\n",
            "\n",
            "Title: How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks\n",
            "Authors: Rahul Ramachandran, Ali Garjani, Roman Bachmann, Andrei Atanov, Oƒüuzhan Fatih Kar, Amir Zamir\n",
            "Venue: arXiv (Preprint) (Preprint)\n",
            "Publication Date: 2025-07-02\n",
            "Relevance to Your Research: 1.00\n",
            "\n",
            "DOI/URL: arXiv:2507.01799v1\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training\n",
            "Authors: Ismail Labiad, Mathurin Videau, Matthieu Kowalski, Marc Schoenauer, Alessandro Leite, Julia Kempe, Olivier Teytaud\n",
            "Venue: arXiv (Preprint) (Preprint)\n",
            "Publication Date: 2025-07-02\n",
            "Relevance to Your Research: 1.00\n",
            "\n",
            "DOI/URL: arXiv:2507.01487v1\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: A new efficient RPKI Design\n",
            "Authors:...\n",
            "\n",
            "**Recommendations:**\n",
            "- Focus on interdisciplinary approaches combining your expertise areas\n",
            "- Consider collaborative research opportunities with researchers working on similar problems\n",
            "- Stay updated with recent developments in your specific research domains\n",
            "\n",
            "**Note:** For more detailed AI-powered analysis, ensure your OpenAI API has sufficient credits.\n",
            "\n",
            "\n",
            "‚úÖ SYSTEM TEST SUCCESSFUL!\n",
            "\n",
            "üéØ READY TO DISCOVER YOUR NEXT BREAKTHROUGH! üöÄ\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üéä PERSONALIZED RESEARCH DISCOVERY SYSTEM - COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\"\"\n",
        "üìä SYSTEM SUMMARY:\n",
        "‚îú‚îÄ‚îÄ üë§ Researcher: {your_profile['name']}\n",
        "‚îú‚îÄ‚îÄ üÜî ORCID ID: {your_profile['orcid_id']}\n",
        "‚îú‚îÄ‚îÄ üìö Your Publications: {len(your_profile['publications'])} ({len(your_profile['journal_papers'])} journals, {len(your_profile['conference_papers'])} conferences)\n",
        "‚îú‚îÄ‚îÄ üîç Recent Papers Found: {len(recent_papers)}\n",
        "‚îú‚îÄ‚îÄ üéØ Highly Relevant: {len([p for p in recent_papers if p['relevance_score'] > 0.7])}\n",
        "‚îú‚îÄ‚îÄ üîë Research Keywords: {len(your_profile['keywords'])}\n",
        "‚îú‚îÄ‚îÄ üí¨ RAG Vector Database: {db.index.ntotal} vectors\n",
        "‚îî‚îÄ‚îÄ üìÑ Export Files: 5 files generated\n",
        "\n",
        "üöÄ READY-TO-USE FUNCTIONS:\n",
        "‚îú‚îÄ‚îÄ ask_anshul_assistant('your question')\n",
        "‚îú‚îÄ‚îÄ query_anshul_research_assistant()\n",
        "‚îú‚îÄ‚îÄ fetch_recent_papers_for_anshul()\n",
        "‚îú‚îÄ‚îÄ export_to_bibtex()\n",
        "‚îú‚îÄ‚îÄ export_to_csv()\n",
        "‚îî‚îÄ‚îÄ create_research_dashboard_data()\n",
        "\n",
        "üéØ IMMEDIATE NEXT STEPS:\n",
        "1. Try the sample queries above\n",
        "2. Review your research report (anshul_research_report.md)\n",
        "3. Check exported BibTeX file for relevant papers\n",
        "4. Set up weekly automated runs\n",
        "5. Integrate with your reference manager\n",
        "\n",
        "üí° ADVANCED FEATURES:\n",
        "‚Ä¢ Personalized relevance scoring based on your publications\n",
        "‚Ä¢ Multi-format export (BibTeX, CSV, JSON)\n",
        "‚Ä¢ Research trend analysis\n",
        "‚Ä¢ Collaboration opportunity identification\n",
        "‚Ä¢ Alert system for new papers\n",
        "\n",
        "üîÑ MAINTENANCE:\n",
        "‚Ä¢ Run weekly to stay updated\n",
        "‚Ä¢ Adjust relevance thresholds as needed\n",
        "‚Ä¢ Add new data sources\n",
        "‚Ä¢ Update research keywords based on new interests\n",
        "\n",
        "‚úÖ SYSTEM STATUS: FULLY OPERATIONAL AND READY FOR USE!\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\nüéâ Congratulations! Your personalized research discovery system is ready!\")\n",
        "print(\"üöÄ Start exploring with: ask_anshul_assistant('What should I research next?')\")\n",
        "\n",
        "# Test the complete system one final time\n",
        "print(\"\\nüß™ FINAL SYSTEM TEST:\")\n",
        "final_test_query = \"Based on my research profile and recent papers, what are the top 3 research directions I should focus on in the next year?\"\n",
        "print(f\"Query: {final_test_query}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "try:\n",
        "    final_response = ask_anshul_assistant(final_test_query)\n",
        "    print(final_response)\n",
        "    print(\"\\n‚úÖ SYSTEM TEST SUCCESSFUL!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå System test failed: {e}\")\n",
        "    print(\"Please check your OpenAI API key and internet connection.\")\n",
        "\n",
        "print(\"\\nüéØ READY TO DISCOVER YOUR NEXT BREAKTHROUGH! üöÄ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APaySaLJ1bUp"
      },
      "source": [
        "Final CELL: Download all files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "WdLkTjC-1UFw",
        "outputId": "d913f929-6211-4df5-9522-82681aa97e3f"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_9e4e7087-0ecb-4d66-a980-931952b45faa\", \"anshul_research_report.md\", 5781)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Downloaded: anshul_research_report.md\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_b2684825-6922-4918-8ac9-36a317a1f299\", \"anshul_research_corpus.txt\", 56096)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Downloaded: anshul_research_corpus.txt\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_80c4a380-56a0-4b54-bf9e-42325b9b73ce\", \"anshul_recent_papers.bib\", 6861)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Downloaded: anshul_recent_papers.bib\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_4a4371b4-b548-4ea5-acc0-b83da446e7cf\", \"anshul_recent_papers.csv\", 13764)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Downloaded: anshul_recent_papers.csv\n"
          ]
        }
      ],
      "source": [
        "# Download all generated files\n",
        "from google.colab import files\n",
        "\n",
        "files_to_download = [\n",
        "    'anshul_research_report.md',\n",
        "    'anshul_research_corpus.txt',\n",
        "    'anshul_recent_papers.bib',\n",
        "    'anshul_recent_papers.csv'\n",
        "]\n",
        "\n",
        "for filename in files_to_download:\n",
        "    try:\n",
        "        files.download(filename)\n",
        "        print(f\"‚úÖ Downloaded: {filename}\")\n",
        "    except:\n",
        "        print(f\"‚ùå File not found: {filename}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
