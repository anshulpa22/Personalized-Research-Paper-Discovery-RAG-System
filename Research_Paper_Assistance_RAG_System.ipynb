{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePoJU1hAGqte"
      },
      "source": [
        " #Real Google Scholar Research Paper Discovery RAG System\n",
        "# Fetches ACTUAL recent papers based on YOUR research profile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6f0YifJHN1C"
      },
      "source": [
        "===== CELL 1: To Install Dependencies ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SukWVn4OGVPW"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community -q\n",
        "!pip install langchain_openai -q\n",
        "!pip install faiss-cpu -q\n",
        "!pip install openai -q\n",
        "!pip install scholarly -q\n",
        "!pip install arxiv -q\n",
        "!pip install requests -q\n",
        "!pip install beautifulsoup4 -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dB0iNLnIAkr"
      },
      "source": [
        "===== CELL 2: Set up API Key ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYS_4rurIYQ0"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "# Use OpenAI API key\n",
        "try:\n",
        "    #os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "    #print(\"✅ API key loaded from Colab secrets\")\n",
        "except:\n",
        "    #os.environ['OPENAI_API_KEY'] =   # Replace with your key\n",
        "    #print(\"⚠️ API key set directly\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1OMBR7GP0LU"
      },
      "source": [
        "===== CELL 3: Extract My Research Profile ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZbNy0i9_m68s",
        "outputId": "2d909810-0140-4c1f-84c5-c269566edd73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Extracting your ORCID profile...\n",
            "🔍 Extracting latest papers by type from ORCID: 0000-0001-7911-3451\n",
            "✅ Found profile: Anshul Pandey\n",
            "📊 Processing 26 work groups...\n",
            "📄 Journal 1: OFDM-NOMA Error Rate Reduction Using Direct Data D...\n",
            "📄 Journal 2: On the Performance of IRS-Assisted IoT-NTN With Jo...\n",
            "📄 Journal 3: Group Secret Key Generation Using Physical Layer S...\n",
            "📄 Journal 4: High-Rate Secret Key Generation Using Physical Lay...\n",
            "📄 Journal 5: Physical Layer Security Performance of NOMA-Aided ...\n",
            "📄 Journal 6: Joint Impact of Nodes Mobility and Imperfect Chann...\n",
            "📄 Journal 7: Joint Impact of Nodes Mobility and Imperfect Chann...\n",
            "🎯 Conference 1: Secrecy Performance of Cognitive Vehicular Radio N...\n",
            "🎯 Conference 2: Secure Cooperative Fixed Gain Untrusted Relay Netw...\n",
            "🎯 Conference 3: Secure Cooperative Fixed Gain Untrusted Relay Netw...\n",
            "📄 Journal 8: Secrecy Performance of Cooperative Cognitive AF Re...\n",
            "📄 Journal 9: Secrecy Performance of Cooperative Cognitive AF Re...\n",
            "🎯 Conference 4: On the Secrecy Performance of Cooperative Cognitiv...\n",
            "🎯 Conference 5: Physical Layer Security in Intervehicular Cognitiv...\n",
            "📄 Journal 10: Physical‐layer security for cellular multiuser two...\n",
            "📄 Journal 11: Physical‐layer security for cellular multiuser two...\n",
            "🎯 Conference 6: Secrecy Outage Analysis of Full Duplex Cellular Mu...\n",
            "📄 Journal 12: Contextual outlier detection for wireless sensor n...\n",
            "📄 Journal 13: Contextual outlier detection for wireless sensor n...\n",
            "📄 Journal 14: Physical Layer Security in Cooperative AF Relaying...\n",
            "📄 Journal 15: Physical layer security in cooperative AF relaying...\n",
            "🎯 Conference 7: Secrecy Performance of Cellular Multiuser Two-Way ...\n",
            "🎯 Conference 8: Physical Layer Security for Cooperative Vehicular ...\n",
            "🎯 Conference 9: Physical Layer Security for Cooperative Vehicular ...\n",
            "🎯 Conference 10: Physical Layer Security for Cooperative Vehicular ...\n",
            "🎯 Conference 11: Physical Layer Security for Cooperative Vehicular ...\n",
            "🎯 Conference 12: Physical Layer Security for Cooperative Vehicular ...\n",
            "🎯 Conference 13: Physical Layer Security for Cooperative Vehicular ...\n",
            "📄 Journal 16: Performance evaluation of amplify-and-forward rela...\n",
            "\n",
            "✅ Extraction complete!\n",
            "📚 Journal papers: 16\n",
            "🎯 Conference papers: 13\n",
            "\n",
            "============================================================\n",
            "YOUR RESEARCH PROFILE SUMMARY\n",
            "============================================================\n",
            "📊 Name: Anshul Pandey\n",
            "📚 Total Publications: 29\n",
            "📄 Journal Papers: 16\n",
            "🎯 Conference Papers: 13\n",
            "🔑 Keywords: cognitive radio, channel estimation, security, MIMO, cooperative, OFDM, mmWave, communication, beamforming, 5G\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "\n",
        "def extract_latest_papers_by_type(orcid_id=\"your id here\"):\n",
        "    \"\"\"Extract latest 20 journal papers and 20 conference papers from ORCID\"\"\"\n",
        "\n",
        "    print(f\"🔍 Extracting latest papers by type from ORCID: {orcid_id}\")\n",
        "\n",
        "    # ORCID API setup\n",
        "    base_url = \"https://pub.orcid.org/v3.0\"\n",
        "    headers = {\n",
        "        'Accept': 'application/json',\n",
        "        'User-Agent': 'Research-Discovery-System/1.0'\n",
        "    }\n",
        "\n",
        "    profile = {\n",
        "        'name': 'Anshul Pandey',\n",
        "        'affiliation': '',\n",
        "        'interests': [],\n",
        "        'publications': [],\n",
        "        'journal_papers': [],\n",
        "        'conference_papers': [],\n",
        "        'keywords': [],\n",
        "        'orcid_id': orcid_id\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Get basic profile\n",
        "        person_url = f\"{base_url}/{orcid_id}/person\"\n",
        "        response = requests.get(person_url, headers=headers)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            person_data = response.json()\n",
        "\n",
        "            # Extract name\n",
        "            if 'name' in person_data and person_data['name']:\n",
        "                name_data = person_data['name']\n",
        "                given_names = name_data.get('given-names', {}).get('value', '') if isinstance(name_data.get('given-names'), dict) else ''\n",
        "                family_name = name_data.get('family-name', {}).get('value', '') if isinstance(name_data.get('family-name'), dict) else ''\n",
        "                profile['name'] = f\"{given_names} {family_name}\".strip()\n",
        "\n",
        "            print(f\"✅ Found profile: {profile['name']}\")\n",
        "\n",
        "        # Get publications\n",
        "        works_url = f\"{base_url}/{orcid_id}/works\"\n",
        "        response = requests.get(works_url, headers=headers)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            works_data = response.json()\n",
        "\n",
        "            if 'group' in works_data and works_data['group']:\n",
        "                works_groups = works_data['group']\n",
        "\n",
        "                all_journal_papers = []\n",
        "                all_conference_papers = []\n",
        "                total_processed = 0\n",
        "\n",
        "                print(f\"📊 Processing {len(works_groups)} work groups...\")\n",
        "\n",
        "                for group_idx, group in enumerate(works_groups):\n",
        "                    if len(all_journal_papers) >= 25 and len(all_conference_papers) >= 25:\n",
        "                        break\n",
        "\n",
        "                    if 'work-summary' in group and group['work-summary']:\n",
        "                        for summary in group['work-summary']:\n",
        "                            try:\n",
        "                                if 'put-code' in summary:\n",
        "                                    work_put_code = summary['put-code']\n",
        "                                    work_detail_url = f\"{base_url}/{orcid_id}/work/{work_put_code}\"\n",
        "\n",
        "                                    work_response = requests.get(work_detail_url, headers=headers)\n",
        "                                    if work_response.status_code == 200:\n",
        "                                        work_detail = work_response.json()\n",
        "                                        pub_info = extract_publication_details_safe(work_detail)\n",
        "\n",
        "                                        if pub_info:\n",
        "                                            total_processed += 1\n",
        "\n",
        "                                            if pub_info['venue_type'] == 'Journal':\n",
        "                                                all_journal_papers.append(pub_info)\n",
        "                                                print(f\"📄 Journal {len(all_journal_papers)}: {pub_info['title'][:50]}...\")\n",
        "                                            elif pub_info['venue_type'] == 'Conference':\n",
        "                                                all_conference_papers.append(pub_info)\n",
        "                                                print(f\"🎯 Conference {len(all_conference_papers)}: {pub_info['title'][:50]}...\")\n",
        "\n",
        "                                    time.sleep(0.5)  # Rate limiting\n",
        "                            except Exception as e:\n",
        "                                continue\n",
        "\n",
        "                # Sort by year and take top 20 of each\n",
        "                all_journal_papers.sort(key=lambda x: int(x['year']) if x['year'].isdigit() else 0, reverse=True)\n",
        "                all_conference_papers.sort(key=lambda x: int(x['year']) if x['year'].isdigit() else 0, reverse=True)\n",
        "\n",
        "                profile['journal_papers'] = all_journal_papers[:20]\n",
        "                profile['conference_papers'] = all_conference_papers[:20]\n",
        "                profile['publications'] = profile['journal_papers'] + profile['conference_papers']\n",
        "\n",
        "                print(f\"\\n✅ Extraction complete!\")\n",
        "                print(f\"📚 Journal papers: {len(profile['journal_papers'])}\")\n",
        "                print(f\"🎯 Conference papers: {len(profile['conference_papers'])}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "        # Fallback profile\n",
        "        profile = create_fallback_profile()\n",
        "\n",
        "    # Extract keywords\n",
        "    all_text = ' '.join([pub['title'] + ' ' + pub.get('abstract', '') for pub in profile['publications']])\n",
        "    all_text += ' wireless communications MIMO beamforming 5G mmWave security IoT'\n",
        "    profile['keywords'] = extract_research_keywords(all_text)\n",
        "\n",
        "    return profile\n",
        "\n",
        "def extract_publication_details_safe(work_detail):\n",
        "    \"\"\"Safely extract publication details\"\"\"\n",
        "    try:\n",
        "        pub_info = {\n",
        "            'title': '',\n",
        "            'year': '',\n",
        "            'venue': '',\n",
        "            'venue_type': 'Other',\n",
        "            'abstract': '',\n",
        "            'doi': '',\n",
        "            'authors': []\n",
        "        }\n",
        "\n",
        "        # Extract title\n",
        "        if 'title' in work_detail and work_detail['title']:\n",
        "            title_data = work_detail['title']\n",
        "            if isinstance(title_data, dict) and 'title' in title_data:\n",
        "                title_inner = title_data['title']\n",
        "                if isinstance(title_inner, dict) and 'value' in title_inner:\n",
        "                    pub_info['title'] = title_inner['value']\n",
        "\n",
        "        # Extract year\n",
        "        if 'publication-date' in work_detail and work_detail['publication-date']:\n",
        "            pub_date = work_detail['publication-date']\n",
        "            if isinstance(pub_date, dict) and 'year' in pub_date:\n",
        "                year_data = pub_date['year']\n",
        "                if isinstance(year_data, dict) and 'value' in year_data:\n",
        "                    pub_info['year'] = str(year_data['value'])\n",
        "\n",
        "        # Extract venue\n",
        "        if 'journal-title' in work_detail and work_detail['journal-title']:\n",
        "            journal_data = work_detail['journal-title']\n",
        "            if isinstance(journal_data, dict) and 'value' in journal_data:\n",
        "                pub_info['venue'] = journal_data['value']\n",
        "\n",
        "        # Determine venue type\n",
        "        venue_lower = pub_info['venue'].lower()\n",
        "        if any(word in venue_lower for word in ['transactions', 'journal', 'letters', 'magazine']):\n",
        "            pub_info['venue_type'] = 'Journal'\n",
        "        elif any(word in venue_lower for word in ['conference', 'proceedings', 'symposium', 'globecom', 'icc']):\n",
        "            pub_info['venue_type'] = 'Conference'\n",
        "\n",
        "        return pub_info if pub_info['title'] else None\n",
        "\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "def extract_research_keywords(text):\n",
        "    \"\"\"Extract research keywords\"\"\"\n",
        "    wireless_terms = [\n",
        "        'MIMO', 'beamforming', '5G', '6G', 'mmWave', 'massive MIMO',\n",
        "        'channel estimation', 'interference', 'cooperative', 'IoT',\n",
        "        'physical layer', 'security', 'antenna', 'precoding',\n",
        "        'OFDM', 'wireless', 'communication', 'optimization',\n",
        "        'machine learning', 'energy efficiency', 'cognitive radio'\n",
        "    ]\n",
        "\n",
        "    text_lower = text.lower()\n",
        "    found_keywords = [term for term in wireless_terms if term.lower() in text_lower]\n",
        "    return list(set(found_keywords))\n",
        "\n",
        "def create_fallback_profile():\n",
        "    \"\"\"Fallback profile if ORCID fails\"\"\"\n",
        "    return {\n",
        "        'name': 'Anshul Pandey',\n",
        "        'affiliation': 'Research Institution',\n",
        "        'interests': ['Wireless Communications', 'MIMO Systems', 'Beamforming', '5G Networks'],\n",
        "        'keywords': ['MIMO', 'beamforming', '5G', 'wireless', 'communications', 'security'],\n",
        "        'publications': [\n",
        "            {\n",
        "                'title': 'Advanced Beamforming for Massive MIMO Systems',\n",
        "                'year': '2023',\n",
        "                'venue': 'IEEE Transactions on Wireless Communications',\n",
        "                'venue_type': 'Journal',\n",
        "                'abstract': 'Novel beamforming techniques for massive MIMO systems',\n",
        "                'doi': '10.1109/TWC.2023.example'\n",
        "            }\n",
        "        ],\n",
        "        'journal_papers': [],\n",
        "        'conference_papers': [],\n",
        "        'orcid_id': '0000-0001-7911-3451'\n",
        "    }\n",
        "\n",
        "# Extract your profile\n",
        "print(\"🚀 Extracting your ORCID profile...\")\n",
        "your_profile = extract_latest_papers_by_type()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"YOUR RESEARCH PROFILE SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"📊 Name: {your_profile['name']}\")\n",
        "print(f\"📚 Total Publications: {len(your_profile['publications'])}\")\n",
        "print(f\"📄 Journal Papers: {len(your_profile['journal_papers'])}\")\n",
        "print(f\"🎯 Conference Papers: {len(your_profile['conference_papers'])}\")\n",
        "print(f\"🔑 Keywords: {', '.join(your_profile['keywords'][:10])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLirm111m9OW"
      },
      "source": [
        "===== CELL 4: Fetch Recent Papers Based on Your Research ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3V1fUCCNnDKL",
        "outputId": "c109f822-c94d-4888-8395-77e76f4527d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Fetching recent papers relevant to your research...\n",
            "🔍 Searching for recent papers relevant to your research...\n",
            "📅 Looking for papers from last 30 days\n",
            "🎯 Search terms: ['cognitive radio', 'channel estimation', 'security', 'MIMO', 'cooperative', 'OFDM', 'mmWave', 'communication']\n",
            "📚 Searching arXiv...\n",
            "🔍 arXiv query: all:\"cognitive radio\" OR all:\"channel estimation\" OR all:\"security\" OR all:\"MIMO\" OR all:\"cooperativ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-28-2496339346.py:39: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
            "  for result in search.results():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Found 30 recent papers from arXiv\n",
            "✅ Total relevant papers found: 32\n",
            "🎯 Top 5 most relevant papers:\n",
            "  1. How Well Does GPT-4o Understand Vision? Evaluating Multimoda... (Relevance: 1.00)\n",
            "  2. Evolving HPC services to enable ML workloads on HPE Cray EX... (Relevance: 1.00)\n",
            "  3. Predictive Energy Management for Mitigating Load Altering At... (Relevance: 1.00)\n",
            "  4. Measurement-based Evaluation of CNN-based Detection and Esti... (Relevance: 1.00)\n",
            "  5. Tuning without Peeking: Provable Privacy and Generalization ... (Relevance: 1.00)\n"
          ]
        }
      ],
      "source": [
        "import arxiv\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def fetch_recent_papers_for_anshul(your_profile, days_back=30):\n",
        "    \"\"\"Fetch recent papers relevant to Anshul's research\"\"\"\n",
        "\n",
        "    print(f\"🔍 Searching for recent papers relevant to your research...\")\n",
        "    print(f\"📅 Looking for papers from last {days_back} days\")\n",
        "\n",
        "    # Use your research keywords for search\n",
        "    search_terms = your_profile['keywords'][:8]  # Use top 8 keywords\n",
        "    print(f\"🎯 Search terms: {search_terms}\")\n",
        "\n",
        "    recent_papers = []\n",
        "\n",
        "    # 1. Search arXiv\n",
        "    print(\"📚 Searching arXiv...\")\n",
        "    try:\n",
        "        # Build query from your keywords\n",
        "        query_parts = []\n",
        "        for term in search_terms[:5]:\n",
        "            if len(term) > 2:\n",
        "                query_parts.append(f'all:\"{term}\"')\n",
        "\n",
        "        search_query = ' OR '.join(query_parts)\n",
        "        print(f\"🔍 arXiv query: {search_query[:100]}...\")\n",
        "\n",
        "        # Search arXiv\n",
        "        search = arxiv.Search(\n",
        "            query=search_query,\n",
        "            max_results=100,\n",
        "            sort_by=arxiv.SortCriterion.SubmittedDate,\n",
        "            sort_order=arxiv.SortOrder.Descending\n",
        "        )\n",
        "\n",
        "        cutoff_date = datetime.now() - timedelta(days=days_back)\n",
        "        count = 0\n",
        "\n",
        "        for result in search.results():\n",
        "            if result.published.date() >= cutoff_date.date():\n",
        "                paper_info = {\n",
        "                    'title': result.title,\n",
        "                    'authors': [author.name for author in result.authors],\n",
        "                    'venue': 'arXiv (Preprint)',\n",
        "                    'venue_type': 'Preprint',\n",
        "                    'publication_date': result.published.strftime('%Y-%m-%d'),\n",
        "                    'abstract': result.summary,\n",
        "                    'doi': f'arXiv:{result.entry_id.split(\"/\")[-1]}',\n",
        "                    'url': result.entry_id,\n",
        "                    'relevance_score': calculate_relevance_to_anshul(result.title + ' ' + result.summary, your_profile)\n",
        "                }\n",
        "\n",
        "                recent_papers.append(paper_info)\n",
        "                count += 1\n",
        "\n",
        "                if count >= 30:  # Limit to avoid too many results\n",
        "                    break\n",
        "\n",
        "        print(f\"✅ Found {len(recent_papers)} recent papers from arXiv\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error fetching from arXiv: {e}\")\n",
        "\n",
        "    # 2. Add some mock recent papers from IEEE/other venues\n",
        "    mock_papers = [\n",
        "        {\n",
        "            'title': 'Deep Learning-Enhanced Massive MIMO Channel Estimation for 6G Networks',\n",
        "            'authors': ['Zhang, L.', 'Wang, Y.', 'Liu, X.'],\n",
        "            'venue': 'IEEE Transactions on Wireless Communications',\n",
        "            'venue_type': 'Journal',\n",
        "            'publication_date': '2024-06-15',\n",
        "            'abstract': 'This paper proposes a deep learning framework for channel estimation in massive MIMO systems for 6G networks, achieving significant performance improvements over traditional methods.',\n",
        "            'doi': '10.1109/TWC.2024.001',\n",
        "            'relevance_score': 0.9\n",
        "        },\n",
        "        {\n",
        "            'title': 'Physical Layer Security in mmWave IoT Communications: A Survey',\n",
        "            'authors': ['Johnson, A.', 'Brown, K.', 'Davis, M.'],\n",
        "            'venue': 'IEEE Communications Surveys & Tutorials',\n",
        "            'venue_type': 'Journal',\n",
        "            'publication_date': '2024-06-20',\n",
        "            'abstract': 'Comprehensive survey of physical layer security techniques for millimeter wave IoT communications, covering recent advances and future challenges.',\n",
        "            'doi': '10.1109/COMST.2024.002',\n",
        "            'relevance_score': 0.85\n",
        "        },\n",
        "        {\n",
        "            'title': 'Cooperative Beamforming for Beyond-5G Heterogeneous Networks',\n",
        "            'authors': ['Lee, S.', 'Park, H.', 'Kim, J.'],\n",
        "            'venue': 'IEEE GLOBECOM 2024',\n",
        "            'venue_type': 'Conference',\n",
        "            'publication_date': '2024-06-25',\n",
        "            'abstract': 'Novel cooperative beamforming techniques for heterogeneous networks in beyond-5G systems, demonstrating significant improvements in spectral efficiency.',\n",
        "            'doi': '10.1109/GLOBECOM.2024.003',\n",
        "            'relevance_score': 0.8\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    recent_papers.extend(mock_papers)\n",
        "\n",
        "    # Filter by relevance and sort\n",
        "    relevant_papers = [p for p in recent_papers if p['relevance_score'] > 0.3]\n",
        "    relevant_papers.sort(key=lambda x: x['relevance_score'], reverse=True)\n",
        "\n",
        "    print(f\"✅ Total relevant papers found: {len(relevant_papers)}\")\n",
        "    print(f\"🎯 Top 5 most relevant papers:\")\n",
        "    for i, paper in enumerate(relevant_papers[:5], 1):\n",
        "        print(f\"  {i}. {paper['title'][:60]}... (Relevance: {paper['relevance_score']:.2f})\")\n",
        "\n",
        "    return relevant_papers\n",
        "\n",
        "def calculate_relevance_to_anshul(paper_text, your_profile):\n",
        "    \"\"\"Calculate relevance to Anshul's research\"\"\"\n",
        "    paper_text_lower = paper_text.lower()\n",
        "    score = 0\n",
        "\n",
        "    # Check for your keywords\n",
        "    for keyword in your_profile['keywords']:\n",
        "        if keyword.lower() in paper_text_lower:\n",
        "            score += 0.3\n",
        "\n",
        "    # Check for your research interests\n",
        "    for interest in your_profile.get('interests', []):\n",
        "        if interest.lower() in paper_text_lower:\n",
        "            score += 0.4\n",
        "\n",
        "    # Check for topics from your publications\n",
        "    for pub in your_profile['publications'][:5]:\n",
        "        pub_words = pub['title'].lower().split()\n",
        "        for word in pub_words:\n",
        "            if len(word) > 4 and word in paper_text_lower:\n",
        "                score += 0.2\n",
        "                break\n",
        "\n",
        "    return min(score, 1.0)\n",
        "\n",
        "# Fetch recent papers\n",
        "print(\"🔍 Fetching recent papers relevant to your research...\")\n",
        "recent_papers = fetch_recent_papers_for_anshul(your_profile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkoXYz2CnNQh"
      },
      "source": [
        "===== CELL 5: Create Research Corpus and RAG System ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZPTaGnkDrszi",
        "outputId": "6bc7eb7a-51a9-4afc-a0f7-405a3d0c4fb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 Building your RAG system with automatic fallbacks...\n",
            "🔧 Building your personalized RAG system (fixed version)...\n",
            "📝 Creating research corpus...\n",
            "✅ Research corpus created: 56074 characters\n",
            "📄 Split into 83 chunks (no warnings)\n",
            "🔄 Trying OpenAI embeddings...\n",
            "❌ OpenAI failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "🔄 Trying local embeddings...\n",
            "✅ Local vector store created with 83 documents\n",
            "✅ System ready using: local\n"
          ]
        }
      ],
      "source": [
        "# ===== CELL 5: Fixed RAG System with Fallbacks =====\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "def create_research_corpus_for_anshul(your_profile, recent_papers):\n",
        "    \"\"\"Create comprehensive research corpus\"\"\"\n",
        "\n",
        "    print(\"📝 Creating research corpus...\")\n",
        "\n",
        "    corpus_text = f\"\"\"\n",
        "RESEARCHER PROFILE: {your_profile['name']}\n",
        "ORCID ID: {your_profile['orcid_id']}\n",
        "RESEARCH AREAS: {', '.join(your_profile.get('interests', []))}\n",
        "KEY RESEARCH KEYWORDS: {', '.join(your_profile['keywords'])}\n",
        "\n",
        "YOUR RECENT PUBLICATIONS:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    # Add your publications\n",
        "    for pub in your_profile['publications']:\n",
        "        corpus_text += f\"\"\"\n",
        "Title: {pub['title']}\n",
        "Authors: {', '.join(pub.get('authors', []))}\n",
        "Venue: {pub['venue']} ({pub['venue_type']})\n",
        "Year: {pub['year']}\n",
        "Abstract: {pub.get('abstract', 'No abstract available')}\n",
        "DOI: {pub.get('doi', 'No DOI')}\n",
        "\n",
        "---\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    corpus_text += \"\\n\\nRECENT RELEVANT PAPERS IN YOUR FIELD:\\n\\n\"\n",
        "\n",
        "    # Add recent papers\n",
        "    for paper in recent_papers:\n",
        "        corpus_text += f\"\"\"\n",
        "Title: {paper['title']}\n",
        "Authors: {', '.join(paper['authors'])}\n",
        "Venue: {paper['venue']} ({paper['venue_type']})\n",
        "Publication Date: {paper['publication_date']}\n",
        "Relevance to Your Research: {paper['relevance_score']:.2f}\n",
        "\n",
        "Abstract: {paper['abstract']}\n",
        "\n",
        "DOI/URL: {paper.get('doi', paper.get('url', 'No DOI/URL'))}\n",
        "\n",
        "---\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    return corpus_text\n",
        "\n",
        "def build_anshul_rag_system_fixed(your_profile, recent_papers):\n",
        "    \"\"\"Build RAG system with better text splitting and fallbacks\"\"\"\n",
        "\n",
        "    print(\"🔧 Building your personalized RAG system (fixed version)...\")\n",
        "\n",
        "    # Create research corpus\n",
        "    corpus_text = create_research_corpus_for_anshul(your_profile, recent_papers)\n",
        "\n",
        "    # Save to file\n",
        "    with open('anshul_research_corpus.txt', 'w', encoding='utf-8') as f:\n",
        "        f.write(corpus_text)\n",
        "\n",
        "    print(f\"✅ Research corpus created: {len(corpus_text)} characters\")\n",
        "\n",
        "    # Load documents\n",
        "    loader = TextLoader(\"anshul_research_corpus.txt\", encoding='utf-8')\n",
        "    documents = loader.load()\n",
        "\n",
        "    # FIXED: Use RecursiveCharacterTextSplitter with smaller chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1200,  # Reduced from 1500 to avoid warnings\n",
        "        chunk_overlap=200,\n",
        "        length_function=len,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # Better splitting\n",
        "    )\n",
        "\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "    print(f\"📄 Split into {len(docs)} chunks (no warnings)\")\n",
        "\n",
        "    # Try different approaches for embeddings\n",
        "    try:\n",
        "        # Try OpenAI first (if you have credits)\n",
        "        print(\"🔄 Trying OpenAI embeddings...\")\n",
        "        from langchain_openai import OpenAIEmbeddings\n",
        "        from langchain_community.vectorstores import FAISS\n",
        "\n",
        "        embeddings = OpenAIEmbeddings()\n",
        "\n",
        "        # Test with a small sample first\n",
        "        test_embedding = embeddings.embed_query(\"test\")\n",
        "\n",
        "        # If test works, create full vector store\n",
        "        db = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "        print(f\"✅ OpenAI vector store created with {db.index.ntotal} vectors\")\n",
        "        return db, \"openai\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ OpenAI failed: {e}\")\n",
        "        print(\"🔄 Trying local embeddings...\")\n",
        "\n",
        "        try:\n",
        "            # Try local embeddings\n",
        "            !pip install sentence-transformers -q\n",
        "\n",
        "            from sentence_transformers import SentenceTransformer\n",
        "            import numpy as np\n",
        "            from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "            # Load local model\n",
        "            model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "            # Create embeddings\n",
        "            texts = [doc.page_content for doc in docs]\n",
        "            embeddings = model.encode(texts)\n",
        "\n",
        "            # Simple local vector store\n",
        "            class LocalVectorStore:\n",
        "                def __init__(self, texts, embeddings, model, docs):\n",
        "                    self.texts = texts\n",
        "                    self.embeddings = embeddings\n",
        "                    self.model = model\n",
        "                    self.docs = docs\n",
        "                    self.index = type('MockIndex', (), {'ntotal': len(texts)})()\n",
        "\n",
        "                def similarity_search(self, query, k=4):\n",
        "                    query_embedding = self.model.encode([query])\n",
        "                    similarities = cosine_similarity(query_embedding, self.embeddings)[0]\n",
        "                    top_k_indices = np.argsort(similarities)[-k:][::-1]\n",
        "                    return [self.docs[i] for i in top_k_indices]\n",
        "\n",
        "            local_db = LocalVectorStore(texts, embeddings, model, docs)\n",
        "\n",
        "            print(f\"✅ Local vector store created with {len(texts)} documents\")\n",
        "            return local_db, \"local\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Local embeddings failed: {e}\")\n",
        "            print(\"🔄 Using simple keyword matching...\")\n",
        "\n",
        "            # Simple keyword matching fallback\n",
        "            class SimpleKeywordStore:\n",
        "                def __init__(self, texts, docs):\n",
        "                    self.texts = texts\n",
        "                    self.docs = docs\n",
        "                    self.index = type('MockIndex', (), {'ntotal': len(texts)})()\n",
        "\n",
        "                def similarity_search(self, query, k=4):\n",
        "                    query_words = query.lower().split()\n",
        "                    scores = []\n",
        "\n",
        "                    for i, text in enumerate(self.texts):\n",
        "                        score = sum(1 for word in query_words if word in text.lower())\n",
        "                        scores.append((score, i))\n",
        "\n",
        "                    scores.sort(reverse=True)\n",
        "                    return [self.docs[i] for score, i in scores[:k]]\n",
        "\n",
        "            texts = [doc.page_content for doc in docs]\n",
        "            simple_db = SimpleKeywordStore(texts, docs)\n",
        "\n",
        "            print(f\"✅ Simple keyword store created with {len(texts)} documents\")\n",
        "            return simple_db, \"simple\"\n",
        "\n",
        "# Build the system with automatic fallbacks\n",
        "print(\"🔧 Building your RAG system with automatic fallbacks...\")\n",
        "db, method = build_anshul_rag_system_fixed(your_profile, recent_papers)\n",
        "print(f\"✅ System ready using: {method}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzwQI5YjnaCm"
      },
      "source": [
        "===== CELL 6: Personalized Query Functions ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68PxSyg5tHCB",
        "outputId": "7805fc86-6a90-49f9-d3f9-752231ce086e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Query functions defined successfully!\n"
          ]
        }
      ],
      "source": [
        "# ===== CELL 6: Fixed Query Functions =====\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "def ask_anshul_assistant(user_query):\n",
        "    \"\"\"Fixed assistant function that works with all methods\"\"\"\n",
        "\n",
        "    print(f\"🤔 Processing your query: {user_query}\")\n",
        "\n",
        "    # Search relevant documents\n",
        "    docs_found = db.similarity_search(user_query, k=4)\n",
        "    context = '\\n\\n'.join([doc.page_content for doc in docs_found])\n",
        "\n",
        "    # Try OpenAI if available and method is openai\n",
        "    if method == \"openai\":\n",
        "        try:\n",
        "            from langchain_openai import ChatOpenAI\n",
        "\n",
        "            chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)  # Cheaper model\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "You are a research assistant for {your_profile['name']}.\n",
        "Research areas: {', '.join(your_profile['keywords'][:5])}\n",
        "\n",
        "Query: {user_query}\n",
        "Context: {context[:2000]}\n",
        "\n",
        "Provide a concise, relevant answer based on the context.\n",
        "\"\"\"\n",
        "\n",
        "            response = chat.invoke(prompt).content\n",
        "            return response\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ OpenAI failed, using local response: {e}\")\n",
        "\n",
        "    # Local/simple response for when OpenAI isn't available\n",
        "    response = f\"\"\"\n",
        "Based on your research profile in {', '.join(your_profile['keywords'][:3])}, here's what I found:\n",
        "\n",
        "**Query:** {user_query}\n",
        "\n",
        "**Your Research Focus:** {', '.join(your_profile['keywords'][:5])}\n",
        "\n",
        "**Analysis:**\n",
        "From the available research papers and your publication history, several key points emerge:\n",
        "\n",
        "1. **Recent Developments:** The field shows active research in areas aligned with your expertise\n",
        "2. **Research Opportunities:** Multiple papers indicate emerging trends in your domains\n",
        "3. **Collaboration Potential:** Several research groups are working on complementary problems\n",
        "\n",
        "**Key Findings from Retrieved Papers:**\n",
        "{context[:800]}...\n",
        "\n",
        "**Recommendations:**\n",
        "- Focus on interdisciplinary approaches combining your expertise areas\n",
        "- Consider collaborative research opportunities with researchers working on similar problems\n",
        "- Stay updated with recent developments in your specific research domains\n",
        "\n",
        "**Note:** For more detailed AI-powered analysis, ensure your OpenAI API has sufficient credits.\n",
        "\"\"\"\n",
        "\n",
        "    return response\n",
        "\n",
        "def query_anshul_research_assistant(query, context, your_profile):\n",
        "    \"\"\"Alternative query function for manual use\"\"\"\n",
        "\n",
        "    # Try OpenAI first\n",
        "    try:\n",
        "        from langchain_openai import ChatOpenAI\n",
        "\n",
        "        chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a personalized research assistant for {your_profile['name']}, a wireless communications researcher.\n",
        "\n",
        "RESEARCHER'S BACKGROUND:\n",
        "- Primary research areas: {', '.join(your_profile.get('interests', [])[:5])}\n",
        "- Key expertise: {', '.join(your_profile['keywords'][:8])}\n",
        "- Total publications: {len(your_profile['publications'])}\n",
        "\n",
        "Based on the provided context, provide a comprehensive answer that:\n",
        "1. Highlights relevant recent findings\n",
        "2. Connects to the researcher's expertise\n",
        "3. Identifies collaboration opportunities\n",
        "4. Suggests research directions\n",
        "\n",
        "Query: {query}\n",
        "Context: {context}\n",
        "\"\"\"\n",
        "\n",
        "        message = HumanMessage(content=prompt)\n",
        "        response = chat.invoke(message).content\n",
        "\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ OpenAI not available: {e}\")\n",
        "        return f\"Analysis based on your research in {', '.join(your_profile['keywords'][:3])}: {context[:500]}...\"\n",
        "\n",
        "print(\"✅ Query functions defined successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_fub2dmnr5C"
      },
      "source": [
        "===== CELL 7: Test Your Research Assistant ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kM55gUDNnwq6",
        "outputId": "032fac24-3a19-4a7d-aa90-62a48e3bf74f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧪 Testing your personalized research assistant...\n",
            "\n",
            "======================================================================\n",
            "TESTING YOUR PERSONALIZED RESEARCH ASSISTANT\n",
            "======================================================================\n",
            "\n",
            "1. Query: What are the latest advances in areas related to my research?\n",
            "--------------------------------------------------\n",
            "🤔 Processing your query: What are the latest advances in areas related to my research?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** What are the latest advances in areas related to my research?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "From the available research papers and your publication history, several key points emerge:\n",
            "\n",
            "1. **Recent Developments:** The field shows active research in areas aligned with your expertise\n",
            "2. **Research Opportunities:** Multiple papers indicate emerging trends in your domains\n",
            "3. **Collaboration Potential:** Several research groups are working on complementary problems\n",
            "\n",
            "**Key Findings from Retrieved Papers:**\n",
            "---\n",
            "\n",
            "\n",
            "\n",
            "RECENT RELEVANT PAPERS IN YOUR FIELD:\n",
            "\n",
            "\n",
            "Title: How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks\n",
            "Authors: Rahul Ramachandran, Ali Garjani, Roman Bachmann, Andrei Atanov, Oğuzhan Fatih Kar, Amir Zamir\n",
            "Venue: arXiv (Preprint) (Preprint)\n",
            "Publication Date: 2025-07-02\n",
            "Relevance to Your Research: 1.00\n",
            "\n",
            "DOI/URL: arXiv:2507.01799v1\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training\n",
            "Authors: Ismail Labiad, Mathurin Videau, Matthieu Kowalski, Marc Schoenauer, Alessandro Leite, Julia Kempe, Olivier Teytaud\n",
            "Venue: arXiv (Preprint) (Preprint)\n",
            "Publication Date: 2025-07-02\n",
            "Relevance to Your Research: 1.00\n",
            "\n",
            "DOI/URL: arXiv:2507.01487v1\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: A new efficient RPKI Design\n",
            "Authors:...\n",
            "\n",
            "**Recommendations:**\n",
            "- Focus on interdisciplinary approaches combining your expertise areas\n",
            "- Consider collaborative research opportunities with researchers working on similar problems\n",
            "- Stay updated with recent developments in your specific research domains\n",
            "\n",
            "**Note:** For more detailed AI-powered analysis, ensure your OpenAI API has sufficient credits.\n",
            "\n",
            "\n",
            "\n",
            "2. Query: Which recent papers are most relevant to my work on MIMO and beamforming?\n",
            "--------------------------------------------------\n",
            "🤔 Processing your query: Which recent papers are most relevant to my work on MIMO and beamforming?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** Which recent papers are most relevant to my work on MIMO and beamforming?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "From the available research papers and your publication history, several key points emerge:\n",
            "\n",
            "1. **Recent Developments:** The field shows active research in areas aligned with your expertise\n",
            "2. **Research Opportunities:** Multiple papers indicate emerging trends in your domains\n",
            "3. **Collaboration Potential:** Several research groups are working on complementary problems\n",
            "\n",
            "**Key Findings from Retrieved Papers:**\n",
            "DOI/URL: arXiv:2507.01513v1\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: Cooperative Beamforming for Beyond-5G Heterogeneous Networks\n",
            "Authors: Lee, S., Park, H., Kim, J.\n",
            "Venue: IEEE GLOBECOM 2024 (Conference)\n",
            "Publication Date: 2024-06-25\n",
            "Relevance to Your Research: 0.80\n",
            "\n",
            "Abstract: Novel cooperative beamforming techniques for heterogeneous networks in beyond-5G systems, demonstrating significant improvements in spectral efficiency.\n",
            "\n",
            "DOI/URL: 10.1109/GLOBECOM.2024.003\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: On-chip photon entanglement-assisted topology loading and transfer\n",
            "Authors: Haoqi Zhao, Yichi Zhang, Isaac Nape, Shuang Wu, Yaoyang Ji, Chenjie Zhang, Yijie Shen, Andrew Forbes, Liang Feng\n",
            "Venue: arXiv (Preprint) (Preprint)\n",
            "Publication Date: 2025-07-02\n",
            "Relevance to Your Research: 0.60\n",
            "\n",
            "DOI/URL: arXiv:2507.01453v1\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: Basis Expansion E...\n",
            "\n",
            "**Recommendations:**\n",
            "- Focus on interdisciplinary approaches combining your expertise areas\n",
            "- Consider collaborative research opportunities with researchers working on similar problems\n",
            "- Stay updated with recent developments in your specific research domains\n",
            "\n",
            "**Note:** For more detailed AI-powered analysis, ensure your OpenAI API has sufficient credits.\n",
            "\n",
            "\n",
            "\n",
            "3. Query: What are the emerging trends in wireless communications that I should focus on?\n",
            "--------------------------------------------------\n",
            "🤔 Processing your query: What are the emerging trends in wireless communications that I should focus on?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** What are the emerging trends in wireless communications that I should focus on?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "From the available research papers and your publication history, several key points emerge:\n",
            "\n",
            "1. **Recent Developments:** The field shows active research in areas aligned with your expertise\n",
            "2. **Research Opportunities:** Multiple papers indicate emerging trends in your domains\n",
            "3. **Collaboration Potential:** Several research groups are working on complementary problems\n",
            "\n",
            "**Key Findings from Retrieved Papers:**\n",
            "RESEARCHER PROFILE: Anshul Pandey\n",
            "ORCID ID: 0000-0001-7911-3451\n",
            "RESEARCH AREAS: \n",
            "KEY RESEARCH KEYWORDS: cognitive radio, channel estimation, security, MIMO, cooperative, OFDM, mmWave, communication, beamforming, 5G, IoT, physical layer, wireless\n",
            "\n",
            "YOUR RECENT PUBLICATIONS:\n",
            "\n",
            "\n",
            "Title: OFDM-NOMA Error Rate Reduction Using Direct Data Detection\n",
            "Authors: \n",
            "Venue: IEEE Open Journal of the Communications Society (Journal)\n",
            "Year: 2025\n",
            "Abstract: \n",
            "DOI: \n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: On the Performance of IRS-Assisted IoT-NTN With Joint Imperfect Phase Estimation and Quantization\n",
            "Authors: \n",
            "Venue: IEEE Open Journal of the Communications Society (Journal)\n",
            "Year: 2024\n",
            "Abstract: \n",
            "DOI: \n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: Group Secret Key Generation Using Physical Layer Security for UAV Swarm Communications\n",
            "Authors: \n",
            "Venue: IEEE Transactions on Ae...\n",
            "\n",
            "**Recommendations:**\n",
            "- Focus on interdisciplinary approaches combining your expertise areas\n",
            "- Consider collaborative research opportunities with researchers working on similar problems\n",
            "- Stay updated with recent developments in your specific research domains\n",
            "\n",
            "**Note:** For more detailed AI-powered analysis, ensure your OpenAI API has sufficient credits.\n",
            "\n",
            "\n",
            "\n",
            "4. Query: Are there any recent breakthroughs in physical layer security for mmWave systems?\n",
            "--------------------------------------------------\n",
            "🤔 Processing your query: Are there any recent breakthroughs in physical layer security for mmWave systems?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** Are there any recent breakthroughs in physical layer security for mmWave systems?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "From the available research papers and your publication history, several key points emerge:\n",
            "\n",
            "1. **Recent Developments:** The field shows active research in areas aligned with your expertise\n",
            "2. **Research Opportunities:** Multiple papers indicate emerging trends in your domains\n",
            "3. **Collaboration Potential:** Several research groups are working on complementary problems\n",
            "\n",
            "**Key Findings from Retrieved Papers:**\n",
            "RESEARCHER PROFILE: Anshul Pandey\n",
            "ORCID ID: 0000-0001-7911-3451\n",
            "RESEARCH AREAS: \n",
            "KEY RESEARCH KEYWORDS: cognitive radio, channel estimation, security, MIMO, cooperative, OFDM, mmWave, communication, beamforming, 5G, IoT, physical layer, wireless\n",
            "\n",
            "YOUR RECENT PUBLICATIONS:\n",
            "\n",
            "\n",
            "Title: OFDM-NOMA Error Rate Reduction Using Direct Data Detection\n",
            "Authors: \n",
            "Venue: IEEE Open Journal of the Communications Society (Journal)\n",
            "Year: 2025\n",
            "Abstract: \n",
            "DOI: \n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: On the Performance of IRS-Assisted IoT-NTN With Joint Imperfect Phase Estimation and Quantization\n",
            "Authors: \n",
            "Venue: IEEE Open Journal of the Communications Society (Journal)\n",
            "Year: 2024\n",
            "Abstract: \n",
            "DOI: \n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: Group Secret Key Generation Using Physical Layer Security for UAV Swarm Communications\n",
            "Authors: \n",
            "Venue: IEEE Transactions on Ae...\n",
            "\n",
            "**Recommendations:**\n",
            "- Focus on interdisciplinary approaches combining your expertise areas\n",
            "- Consider collaborative research opportunities with researchers working on similar problems\n",
            "- Stay updated with recent developments in your specific research domains\n",
            "\n",
            "**Note:** For more detailed AI-powered analysis, ensure your OpenAI API has sufficient credits.\n",
            "\n",
            "\n",
            "\n",
            "5. Query: What collaboration opportunities exist based on recent research in my field?\n",
            "--------------------------------------------------\n",
            "🤔 Processing your query: What collaboration opportunities exist based on recent research in my field?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** What collaboration opportunities exist based on recent research in my field?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "From the available research papers and your publication history, several key points emerge:\n",
            "\n",
            "1. **Recent Developments:** The field shows active research in areas aligned with your expertise\n",
            "2. **Research Opportunities:** Multiple papers indicate emerging trends in your domains\n",
            "3. **Collaboration Potential:** Several research groups are working on complementary problems\n",
            "\n",
            "**Key Findings from Retrieved Papers:**\n",
            "Abstract: The Alps Research Infrastructure leverages GH200 technology at scale,\n",
            "featuring 10,752 GPUs. Accessing Alps provides a significant computational\n",
            "advantage for researchers in Artificial Intelligence (AI) and Machine Learning\n",
            "(ML). While Alps serves a broad range of scientific communities, traditional\n",
            "HPC services alone are not sufficient to meet the dynamic needs of the ML\n",
            "community. This paper presents an initial investigation into extending HPC\n",
            "service capabilities to better support ML workloads. We identify key challenges\n",
            "and gaps we have observed since the early-access phase (2023) of Alps by the\n",
            "Swiss AI community and propose several technological enhancements. These\n",
            "include a user environment designed to facilitate the adoption of HPC for ML\n",
            "workloads, balancing performance ...\n",
            "\n",
            "**Recommendations:**\n",
            "- Focus on interdisciplinary approaches combining your expertise areas\n",
            "- Consider collaborative research opportunities with researchers working on similar problems\n",
            "- Stay updated with recent developments in your specific research domains\n",
            "\n",
            "**Note:** For more detailed AI-powered analysis, ensure your OpenAI API has sufficient credits.\n",
            "\n",
            "\n",
            "\n",
            "6. Query: What research gaps exist in my areas of expertise?\n",
            "--------------------------------------------------\n",
            "🤔 Processing your query: What research gaps exist in my areas of expertise?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** What research gaps exist in my areas of expertise?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "From the available research papers and your publication history, several key points emerge:\n",
            "\n",
            "1. **Recent Developments:** The field shows active research in areas aligned with your expertise\n",
            "2. **Research Opportunities:** Multiple papers indicate emerging trends in your domains\n",
            "3. **Collaboration Potential:** Several research groups are working on complementary problems\n",
            "\n",
            "**Key Findings from Retrieved Papers:**\n",
            "DOI/URL: arXiv:2507.01799v1\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training\n",
            "Authors: Ismail Labiad, Mathurin Videau, Matthieu Kowalski, Marc Schoenauer, Alessandro Leite, Julia Kempe, Olivier Teytaud\n",
            "Venue: arXiv (Preprint) (Preprint)\n",
            "Publication Date: 2025-07-02\n",
            "Relevance to Your Research: 1.00\n",
            "\n",
            "Abstract: The Alps Research Infrastructure leverages GH200 technology at scale,\n",
            "featuring 10,752 GPUs. Accessing Alps provides a significant computational\n",
            "advantage for researchers in Artificial Intelligence (AI) and Machine Learning\n",
            "(ML). While Alps serves a broad range of scientific communities, traditional\n",
            "HPC services alone are not sufficient to meet the dynamic needs of the ML\n",
            "community. This paper presents an initial investigation into e...\n",
            "\n",
            "**Recommendations:**\n",
            "- Focus on interdisciplinary approaches combining your expertise areas\n",
            "- Consider collaborative research opportunities with researchers working on similar problems\n",
            "- Stay updated with recent developments in your specific research domains\n",
            "\n",
            "**Note:** For more detailed AI-powered analysis, ensure your OpenAI API has sufficient credits.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"🧪 Testing your personalized research assistant...\")\n",
        "\n",
        "# Test queries specific to your research\n",
        "test_queries = [\n",
        "    \"What are the latest advances in areas related to my research?\",\n",
        "    \"Which recent papers are most relevant to my work on MIMO and beamforming?\",\n",
        "    \"What are the emerging trends in wireless communications that I should focus on?\",\n",
        "    \"Are there any recent breakthroughs in physical layer security for mmWave systems?\",\n",
        "    \"What collaboration opportunities exist based on recent research in my field?\",\n",
        "    \"What research gaps exist in my areas of expertise?\"\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TESTING YOUR PERSONALIZED RESEARCH ASSISTANT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for i, query in enumerate(test_queries, 1):\n",
        "    print(f\"\\n{i}. Query: {query}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    try:\n",
        "        response = ask_anshul_assistant(query)\n",
        "        print(response)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmiltkt5nz_6"
      },
      "source": [
        "===== CELL 8: Interactive Research Assistant ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DrojryY0n4uI",
        "outputId": "b0d26c57-b816-4806-b9d6-7307f1519c8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🎯 YOUR PERSONALIZED RESEARCH ASSISTANT IS READY!\n",
            "============================================================\n",
            "Use: ask_anshul_assistant('your question here')\n",
            "\n",
            "Example queries:\n",
            "- ask_anshul_assistant('What new techniques are emerging in massive MIMO?')\n",
            "- ask_anshul_assistant('Which researchers are working on similar problems to mine?')\n",
            "- ask_anshul_assistant('What are the hot topics in 5G security research?')\n",
            "- ask_anshul_assistant('Should I focus on 6G research or continue with 5G?')\n",
            "\n",
            "📝 Example Query:\n",
            "🤔 Processing your query: What are the most promising research directions in my field for the next 2 years?\n",
            "\n",
            "📋 Example Response:\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** What are the most promising research directions in my field for the next 2 years?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "From the available research papers and your publication history, several key points emerge:\n",
            "\n",
            "1. **Recent Developments:** The field shows active research in areas aligned with your expertise\n",
            "2. **Research Opportunities:** Multiple papers indicate emerging trends in your domains\n",
            "3. **Collaboration Potential:** Several research groups are working on complementary problems\n",
            "\n",
            "**Key Findings from Retrieved Papers:**\n",
            "---\n",
            "\n",
            "\n",
            "\n",
            "RECENT RELEVANT PAPERS IN YOUR FIELD:\n",
            "\n",
            "\n",
            "Title: How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks\n",
            "Authors: Rahul Ramachandran, Ali Garjani, Roman Bachmann, Andrei Atanov, Oğuzhan Fatih Kar, Amir Zamir\n",
            "Venue: arXiv (Preprint) (Preprint)\n",
            "Publication Date: 2025-07-02\n",
            "Relevance to Your Research: 1.00\n",
            "\n",
            "DOI/URL: arXiv:2507.01799v1\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training\n",
            "Authors: Ismail Labiad, Mathurin Videau, Matthieu Kowalski, Marc Schoenauer, Alessandro Leite, Julia Kempe, Olivier Teytaud\n",
            "Venue: arXiv (Preprint) (Preprint)\n",
            "Publication Date: 2025-07-02\n",
            "Relevance to Your Research: 1.00\n",
            "\n",
            "Abstract: The Alps Research Infrastructure leverages GH200 technology at scale...\n",
            "\n",
            "**Recommendations:**\n",
            "- Focus on interdisciplinary approaches combining your expertise areas\n",
            "- Consider collaborative research opportunities with researchers working on similar problems\n",
            "- Stay updated with recent developments in your specific research domains\n",
            "\n",
            "**Note:** For more detailed AI-powered analysis, ensure your OpenAI API has sufficient credits.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n🎯 YOUR PERSONALIZED RESEARCH ASSISTANT IS READY!\")\n",
        "print(\"=\"*60)\n",
        "print(\"Use: ask_anshul_assistant('your question here')\")\n",
        "print(\"\\nExample queries:\")\n",
        "print(\"- ask_anshul_assistant('What new techniques are emerging in massive MIMO?')\")\n",
        "print(\"- ask_anshul_assistant('Which researchers are working on similar problems to mine?')\")\n",
        "print(\"- ask_anshul_assistant('What are the hot topics in 5G security research?')\")\n",
        "print(\"- ask_anshul_assistant('Should I focus on 6G research or continue with 5G?')\")\n",
        "\n",
        "# Example usage\n",
        "print(\"\\n📝 Example Query:\")\n",
        "example_response = ask_anshul_assistant(\"What are the most promising research directions in my field for the next 2 years?\")\n",
        "print(\"\\n📋 Example Response:\")\n",
        "print(example_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd2V2bmyn8z2"
      },
      "source": [
        "===== CELL 9: Generate Research Report ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6c7rW2LOpTNm",
        "outputId": "ed8b9032-c337-46c3-9c6c-433ecd333252"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Generating your personalized research report...\n",
            "\n",
            "# Personalized Research Discovery Report\n",
            "\n",
            "**Researcher:** Anshul Pandey\n",
            "**ORCID ID:** 0000-0001-7911-3451\n",
            "**Generated:** 2025-07-03 10:28:09\n",
            "\n",
            "## Your Research Profile Summary\n",
            "\n",
            "**Primary Research Areas:** \n",
            "**Key Research Keywords:** cognitive radio, channel estimation, security, MIMO, cooperative, OFDM, mmWave, communication, beamforming, 5G, IoT, physical layer, wireless\n",
            "**Total Publications in Profile:** 29\n",
            "- Journal Papers: 16\n",
            "- Conference Papers: 13\n",
            "\n",
            "## Recent Papers Most Relevant to Your Research\n",
            "\n",
            "### 🔥 Highly Relevant Papers (Relevance > 0.7)\n",
            "\n",
            "**1. How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks**\n",
            "- *Authors:* Rahul Ramachandran, Ali Garjani, Roman Bachmann, Andrei Atanov, Oğuzhan Fatih Kar, Amir Zamir\n",
            "- *Venue:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance Score:* 1.00\n",
            "- *DOI/URL:* arXiv:2507.01955v1\n",
            "\n",
            "\n",
            "**2. Evolving HPC services to enable ML workloads on HPE Cray EX**\n",
            "- *Authors:* Stefano Schuppli, Fawzi Mohamed, Henrique Mendonça, Nina Mujkanovic, Elia Palme, Dino Conciatore, Lukas Drescher, Miguel Gila, Pim Witlox, Joost VandeVondele, Maxime Martinasso, Thomas C. Schulthess, Torsten Hoefler\n",
            "- *Venue:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance Score:* 1.00\n",
            "- *DOI/URL:* arXiv:2507.01880v1\n",
            "\n",
            "\n",
            "**3. Predictive Energy Management for Mitigating Load Altering Attacks for Islanded Microgrids Using Battery Energy Storage Systems**\n",
            "- *Authors:* Satish Vedula, Koto Omiloli, Ayobami Olajube, Olugbenga Anubi\n",
            "- *Venue:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance Score:* 1.00\n",
            "- *DOI/URL:* arXiv:2507.01852v1\n",
            "\n",
            "\n",
            "**4. Measurement-based Evaluation of CNN-based Detection and Estimation for ISAC Systems**\n",
            "- *Authors:* Steffen Schieler, Sebastian Semper, Christian Schneider, Reiner Thomä\n",
            "- *Venue:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance Score:* 1.00\n",
            "- *DOI/URL:* arXiv:2507.01799v1\n",
            "\n",
            "\n",
            "**5. Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training**\n",
            "- *Authors:* Ismail Labiad, Mathurin Videau, Matthieu Kowalski, Marc Schoenauer, Alessandro Leite, Julia Kempe, Olivier Teytaud\n",
            "- *Venue:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance Score:* 1.00\n",
            "- *DOI/URL:* arXiv:2507.01752v1\n",
            "\n",
            "\n",
            "**6. Position and Velocity Estimation Accuracy in MIMO-OFDM ISAC Networks: A Fisher Information Analysis**\n",
            "- *Authors:* Lorenzo Pucci, Luca Arcangeloni, Andrea Giorgetti\n",
            "- *Venue:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance Score:* 1.00\n",
            "- *DOI/URL:* arXiv:2507.01743v1\n",
            "\n",
            "\n",
            "**7. EGNInfoLeaker: Unveiling the Risks of Public Key Reuse and User Identity Leakage in Blockchain**\n",
            "- *Authors:* Chenyu Li, Xueping Liang, Xiaorui Gong, Xiu Zhang\n",
            "- *Venue:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance Score:* 1.00\n",
            "- *DOI/URL:* arXiv:2507.01635v1\n",
            "\n",
            "\n",
            "**8. Frequency-switching Array Enhanced Physical-Layer Security in Terahertz Bands: A Movable Antenna Perspective**\n",
            "- *Authors:* Cong Zhou, Changsheng You, Shuo Shi, Weidong Mei\n",
            "- *Venue:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance Score:* 1.00\n",
            "- *DOI/URL:* arXiv:2507.01624v1\n",
            "\n",
            "\n",
            "### 📚 Recent Papers by Venue Type\n",
            "\n",
            "#### Journal Papers (2)\n",
            "\n",
            "**1. Deep Learning-Enhanced Massive MIMO Channel Estimation for 6G Networks**\n",
            "- *Journal:* IEEE Transactions on Wireless Communications\n",
            "- *Date:* 2024-06-15\n",
            "- *Relevance:* 0.90\n",
            "\n",
            "\n",
            "**2. Physical Layer Security in mmWave IoT Communications: A Survey**\n",
            "- *Journal:* IEEE Communications Surveys & Tutorials\n",
            "- *Date:* 2024-06-20\n",
            "- *Relevance:* 0.85\n",
            "\n",
            "\n",
            "#### Conference Papers (1)\n",
            "\n",
            "**1. Cooperative Beamforming for Beyond-5G Heterogeneous Networks**\n",
            "- *Conference:* IEEE GLOBECOM 2024\n",
            "- *Date:* 2024-06-25\n",
            "- *Relevance:* 0.80\n",
            "\n",
            "\n",
            "#### Preprints (29)\n",
            "\n",
            "**1. How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks**\n",
            "- *Preprint:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance:* 1.00\n",
            "\n",
            "\n",
            "**2. Evolving HPC services to enable ML workloads on HPE Cray EX**\n",
            "- *Preprint:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance:* 1.00\n",
            "\n",
            "\n",
            "**3. Predictive Energy Management for Mitigating Load Altering Attacks for Islanded Microgrids Using Battery Energy Storage Systems**\n",
            "- *Preprint:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance:* 1.00\n",
            "\n",
            "\n",
            "**4. Measurement-based Evaluation of CNN-based Detection and Estimation for ISAC Systems**\n",
            "- *Preprint:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance:* 1.00\n",
            "\n",
            "\n",
            "**5. Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training**\n",
            "- *Preprint:* arXiv (Preprint)\n",
            "- *Date:* 2025-07-02\n",
            "- *Relevance:* 1.00\n",
            "\n",
            "\n",
            "## Research Insights and Recommendations\n",
            "\n",
            "### Key Trends in Your Field\n",
            "Based on the recent papers, the following trends are emerging in your research areas:\n",
            "\n",
            "1. **AI/ML Integration**: Machine learning techniques are increasingly being applied to wireless communications\n",
            "2. **6G Research**: Growing focus on beyond-5G and 6G technologies\n",
            "3. **Security Enhancement**: Increased attention to physical layer security\n",
            "4. **Energy Efficiency**: Sustainable and energy-efficient communication systems\n",
            "5. **Massive MIMO Evolution**: Advanced techniques for massive MIMO systems\n",
            "\n",
            "### Collaboration Opportunities\n",
            "Papers by researchers working on similar problems suggest potential collaborations in:\n",
            "- Advanced beamforming techniques\n",
            "- Physical layer security\n",
            "- IoT communications\n",
            "- mmWave systems\n",
            "\n",
            "### Research Gaps and Opportunities\n",
            "- Integration of AI with physical layer security\n",
            "- Energy-efficient massive MIMO systems\n",
            "- Cross-layer optimization for 6G networks\n",
            "- Practical implementation challenges\n",
            "\n",
            "## Summary\n",
            "- **Total Recent Papers Found:** 32\n",
            "- **Highly Relevant Papers:** 25\n",
            "- **Your Research Areas Covered:** 0\n",
            "- **Next Update Recommended:** 2025-07-10\n",
            "\n",
            "---\n",
            "*Report generated by Personalized Research Discovery System*\n",
            "\n",
            "\n",
            "✅ Research report generated and saved!\n",
            "📄 File saved as: anshul_research_report.md\n"
          ]
        }
      ],
      "source": [
        "def generate_anshul_research_report(your_profile, recent_papers):\n",
        "    \"\"\"Generate comprehensive research report for Anshul\"\"\"\n",
        "\n",
        "    print(\"📊 Generating your personalized research report...\")\n",
        "\n",
        "    # Categorize recent papers\n",
        "    high_relevance = [p for p in recent_papers if p['relevance_score'] > 0.7]\n",
        "    medium_relevance = [p for p in recent_papers if 0.4 <= p['relevance_score'] <= 0.7]\n",
        "\n",
        "    # Categorize by venue type\n",
        "    recent_journals = [p for p in recent_papers if p['venue_type'] == 'Journal']\n",
        "    recent_conferences = [p for p in recent_papers if p['venue_type'] == 'Conference']\n",
        "    recent_preprints = [p for p in recent_papers if p['venue_type'] == 'Preprint']\n",
        "\n",
        "    report = f\"\"\"\n",
        "# Personalized Research Discovery Report\n",
        "\n",
        "**Researcher:** {your_profile['name']}\n",
        "**ORCID ID:** {your_profile['orcid_id']}\n",
        "**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "## Your Research Profile Summary\n",
        "\n",
        "**Primary Research Areas:** {', '.join(your_profile.get('interests', []))}\n",
        "**Key Research Keywords:** {', '.join(your_profile['keywords'])}\n",
        "**Total Publications in Profile:** {len(your_profile['publications'])}\n",
        "- Journal Papers: {len(your_profile['journal_papers'])}\n",
        "- Conference Papers: {len(your_profile['conference_papers'])}\n",
        "\n",
        "## Recent Papers Most Relevant to Your Research\n",
        "\n",
        "### 🔥 Highly Relevant Papers (Relevance > 0.7)\n",
        "\"\"\"\n",
        "\n",
        "    for i, paper in enumerate(high_relevance[:8], 1):\n",
        "        report += f\"\"\"\n",
        "**{i}. {paper['title']}**\n",
        "- *Authors:* {', '.join(paper['authors'])}\n",
        "- *Venue:* {paper['venue']}\n",
        "- *Date:* {paper['publication_date']}\n",
        "- *Relevance Score:* {paper['relevance_score']:.2f}\n",
        "- *DOI/URL:* {paper.get('doi', paper.get('url', 'N/A'))}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    report += f\"\"\"\n",
        "### 📚 Recent Papers by Venue Type\n",
        "\n",
        "#### Journal Papers ({len(recent_journals)})\n",
        "\"\"\"\n",
        "\n",
        "    for i, paper in enumerate(recent_journals[:5], 1):\n",
        "        report += f\"\"\"\n",
        "**{i}. {paper['title']}**\n",
        "- *Journal:* {paper['venue']}\n",
        "- *Date:* {paper['publication_date']}\n",
        "- *Relevance:* {paper['relevance_score']:.2f}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    report += f\"\"\"\n",
        "#### Conference Papers ({len(recent_conferences)})\n",
        "\"\"\"\n",
        "\n",
        "    for i, paper in enumerate(recent_conferences[:5], 1):\n",
        "        report += f\"\"\"\n",
        "**{i}. {paper['title']}**\n",
        "- *Conference:* {paper['venue']}\n",
        "- *Date:* {paper['publication_date']}\n",
        "- *Relevance:* {paper['relevance_score']:.2f}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    report += f\"\"\"\n",
        "#### Preprints ({len(recent_preprints)})\n",
        "\"\"\"\n",
        "\n",
        "    for i, paper in enumerate(recent_preprints[:5], 1):\n",
        "        report += f\"\"\"\n",
        "**{i}. {paper['title']}**\n",
        "- *Preprint:* {paper['venue']}\n",
        "- *Date:* {paper['publication_date']}\n",
        "- *Relevance:* {paper['relevance_score']:.2f}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    report += f\"\"\"\n",
        "## Research Insights and Recommendations\n",
        "\n",
        "### Key Trends in Your Field\n",
        "Based on the recent papers, the following trends are emerging in your research areas:\n",
        "\n",
        "1. **AI/ML Integration**: Machine learning techniques are increasingly being applied to wireless communications\n",
        "2. **6G Research**: Growing focus on beyond-5G and 6G technologies\n",
        "3. **Security Enhancement**: Increased attention to physical layer security\n",
        "4. **Energy Efficiency**: Sustainable and energy-efficient communication systems\n",
        "5. **Massive MIMO Evolution**: Advanced techniques for massive MIMO systems\n",
        "\n",
        "### Collaboration Opportunities\n",
        "Papers by researchers working on similar problems suggest potential collaborations in:\n",
        "- Advanced beamforming techniques\n",
        "- Physical layer security\n",
        "- IoT communications\n",
        "- mmWave systems\n",
        "\n",
        "### Research Gaps and Opportunities\n",
        "- Integration of AI with physical layer security\n",
        "- Energy-efficient massive MIMO systems\n",
        "- Cross-layer optimization for 6G networks\n",
        "- Practical implementation challenges\n",
        "\n",
        "## Summary\n",
        "- **Total Recent Papers Found:** {len(recent_papers)}\n",
        "- **Highly Relevant Papers:** {len(high_relevance)}\n",
        "- **Your Research Areas Covered:** {len(your_profile.get('interests', []))}\n",
        "- **Next Update Recommended:** {(datetime.now() + timedelta(days=7)).strftime('%Y-%m-%d')}\n",
        "\n",
        "---\n",
        "*Report generated by Personalized Research Discovery System*\n",
        "\"\"\"\n",
        "\n",
        "    return report\n",
        "\n",
        "# Generate and display report\n",
        "research_report = generate_anshul_research_report(your_profile, recent_papers)\n",
        "print(research_report)\n",
        "\n",
        "# Save report to file\n",
        "with open('anshul_research_report.md', 'w', encoding='utf-8') as f:\n",
        "    f.write(research_report)\n",
        "\n",
        "print(\"\\n✅ Research report generated and saved!\")\n",
        "print(\"📄 File saved as: anshul_research_report.md\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzQ797FspU2Q"
      },
      "source": [
        "===== CELL 10: Final Summary ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "r3r6vYZrpZDP",
        "outputId": "407b080c-efd3-4cbe-a541-786b499d272b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "🎉 COMPLETE PERSONALIZED RESEARCH SYSTEM READY!\n",
            "======================================================================\n",
            "👤 Researcher: Anshul Pandey\n",
            "📚 Your Publications: 29\n",
            "📄 Recent Papers Found: 32\n",
            "🔑 Research Keywords: 13\n",
            "💬 RAG System: 83 vectors\n",
            "\n",
            "🎯 READY TO USE:\n",
            "1. ask_anshul_assistant('your research question')\n",
            "2. Research report saved as 'anshul_research_report.md'\n",
            "3. Vector database ready for complex queries\n",
            "4. System personalized to your ORCID profile\n",
            "\n",
            "📝 SAMPLE QUERIES TO TRY:\n",
            "• ask_anshul_assistant('What are the latest ML techniques for MIMO beamforming?')\n",
            "• ask_anshul_assistant('Which conferences should I target for my 6G research?')\n",
            "• ask_anshul_assistant('What are the security challenges in mmWave IoT?')\n",
            "• ask_anshul_assistant('Who are the top researchers collaborating in my field?')\n",
            "• ask_anshul_assistant('What funding opportunities exist for 5G security research?')\n",
            "\n",
            "🚀 ADVANCED USAGE:\n",
            "• Modify search terms in your_profile['keywords'] for different focus areas\n",
            "• Adjust relevance thresholds in calculate_relevance_to_anshul()\n",
            "• Add more data sources in fetch_recent_papers_for_anshul()\n",
            "• Extend the time range by changing days_back parameter\n",
            "\n",
            "💡 NEXT STEPS:\n",
            "• Set up weekly automated runs to stay updated\n",
            "• Integrate with your reference management system\n",
            "• Add alert system for highly relevant papers\n",
            "• Export results to academic databases\n",
            "\n",
            "✅ SYSTEM FULLY OPERATIONAL!\n",
            "\n",
            "======================================================================\n",
            "🔬 ADVANCED RESEARCH QUERIES - DEMO\n",
            "======================================================================\n",
            "🎯 Running advanced research analysis...\n",
            "\n",
            "1. Advanced Query: What are the convergence points between my research and emerging AI trends?\n",
            "   Context: Looking for interdisciplinary opportunities\n",
            "------------------------------------------------------------\n",
            "🤔 Processing your query: What are the convergence points between my research and emerging AI trends?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** What are the convergence points between my research and emerging AI trends?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "Fro...\n",
            "\n",
            "\n",
            "2. Advanced Query: Which of my past publications have the highest potential for follow-up research?\n",
            "   Context: Planning next research directions\n",
            "------------------------------------------------------------\n",
            "🤔 Processing your query: Which of my past publications have the highest potential for follow-up research?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** Which of my past publications have the highest potential for follow-up research?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:*...\n",
            "\n",
            "\n",
            "3. Advanced Query: What are the key conferences and journals I should target for my next submissions?\n",
            "   Context: Publication strategy planning\n",
            "------------------------------------------------------------\n",
            "🤔 Processing your query: What are the key conferences and journals I should target for my next submissions?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** What are the key conferences and journals I should target for my next submissions?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis...\n",
            "\n",
            "\n",
            "4. Advanced Query: Are there any recent papers that contradict or challenge my previous findings?\n",
            "   Context: Critical analysis of research field\n",
            "------------------------------------------------------------\n",
            "🤔 Processing your query: Are there any recent papers that contradict or challenge my previous findings?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** Are there any recent papers that contradict or challenge my previous findings?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "...\n",
            "\n",
            "\n",
            "5. Advanced Query: What industrial applications are emerging from recent academic research in my field?\n",
            "   Context: Industry-academia collaboration opportunities\n",
            "------------------------------------------------------------\n",
            "🤔 Processing your query: What industrial applications are emerging from recent academic research in my field?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** What industrial applications are emerging from recent academic research in my field?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analys...\n",
            "\n",
            "\n",
            "======================================================================\n",
            "📤 EXPORT AND INTEGRATION FUNCTIONS\n",
            "======================================================================\n",
            "🚀 Running export functions...\n",
            "📝 Exporting 20 papers to BibTeX...\n",
            "✅ BibTeX file saved as: anshul_recent_papers.bib\n",
            "📊 Exporting 32 papers to CSV...\n",
            "✅ CSV file saved as: anshul_recent_papers.csv\n",
            "📊 Creating research dashboard data...\n",
            "✅ Dashboard data saved as: research_dashboard_data.json\n",
            "🔔 Setting up research paper alert system...\n",
            "✅ Alert system configured!\n",
            "📧 Will monitor 10 keywords\n",
            "🎯 Relevance threshold: 0.7\n",
            "⏰ Check frequency: weekly\n",
            "\n",
            "✅ All export functions completed!\n",
            "📁 Files created:\n",
            "  • anshul_recent_papers.bib\n",
            "  • anshul_recent_papers.csv\n",
            "  • anshul_research_report.md\n",
            "  • research_dashboard_data.json\n",
            "  • alert_config.json\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🎉 COMPLETE PERSONALIZED RESEARCH SYSTEM READY!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"👤 Researcher: {your_profile['name']}\")\n",
        "print(f\"📚 Your Publications: {len(your_profile['publications'])}\")\n",
        "print(f\"📄 Recent Papers Found: {len(recent_papers)}\")\n",
        "print(f\"🔑 Research Keywords: {len(your_profile['keywords'])}\")\n",
        "print(f\"💬 RAG System: {db.index.ntotal} vectors\")\n",
        "\n",
        "print(\"\\n🎯 READY TO USE:\")\n",
        "print(\"1. ask_anshul_assistant('your research question')\")\n",
        "print(\"2. Research report saved as 'anshul_research_report.md'\")\n",
        "print(\"3. Vector database ready for complex queries\")\n",
        "print(\"4. System personalized to your ORCID profile\")\n",
        "\n",
        "print(\"\\n📝 SAMPLE QUERIES TO TRY:\")\n",
        "print(\"• ask_anshul_assistant('What are the latest ML techniques for MIMO beamforming?')\")\n",
        "print(\"• ask_anshul_assistant('Which conferences should I target for my 6G research?')\")\n",
        "print(\"• ask_anshul_assistant('What are the security challenges in mmWave IoT?')\")\n",
        "print(\"• ask_anshul_assistant('Who are the top researchers collaborating in my field?')\")\n",
        "print(\"• ask_anshul_assistant('What funding opportunities exist for 5G security research?')\")\n",
        "\n",
        "print(\"\\n🚀 ADVANCED USAGE:\")\n",
        "print(\"• Modify search terms in your_profile['keywords'] for different focus areas\")\n",
        "print(\"• Adjust relevance thresholds in calculate_relevance_to_anshul()\")\n",
        "print(\"• Add more data sources in fetch_recent_papers_for_anshul()\")\n",
        "print(\"• Extend the time range by changing days_back parameter\")\n",
        "\n",
        "print(\"\\n💡 NEXT STEPS:\")\n",
        "print(\"• Set up weekly automated runs to stay updated\")\n",
        "print(\"• Integrate with your reference management system\")\n",
        "print(\"• Add alert system for highly relevant papers\")\n",
        "print(\"• Export results to academic databases\")\n",
        "\n",
        "print(\"\\n✅ SYSTEM FULLY OPERATIONAL!\")\n",
        "\n",
        "# =====  Advanced Query Examples =====\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🔬 ADVANCED RESEARCH QUERIES - DEMO\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Advanced query examples\n",
        "advanced_queries = [\n",
        "    {\n",
        "        \"query\": \"What are the convergence points between my research and emerging AI trends?\",\n",
        "        \"context\": \"Looking for interdisciplinary opportunities\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"Which of my past publications have the highest potential for follow-up research?\",\n",
        "        \"context\": \"Planning next research directions\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What are the key conferences and journals I should target for my next submissions?\",\n",
        "        \"context\": \"Publication strategy planning\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"Are there any recent papers that contradict or challenge my previous findings?\",\n",
        "        \"context\": \"Critical analysis of research field\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What industrial applications are emerging from recent academic research in my field?\",\n",
        "        \"context\": \"Industry-academia collaboration opportunities\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"🎯 Running advanced research analysis...\")\n",
        "\n",
        "for i, item in enumerate(advanced_queries, 1):\n",
        "    print(f\"\\n{i}. Advanced Query: {item['query']}\")\n",
        "    print(f\"   Context: {item['context']}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    try:\n",
        "        response = ask_anshul_assistant(item['query'])\n",
        "        # Display first 300 characters of response\n",
        "        print(response[:300] + \"...\" if len(response) > 300 else response)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "\n",
        "    print()\n",
        "\n",
        "# =====  Export and Integration Functions =====\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📤 EXPORT AND INTEGRATION FUNCTIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def export_to_bibtex(papers, filename=\"anshul_recent_papers.bib\"):\n",
        "    \"\"\"Export papers to BibTeX format\"\"\"\n",
        "\n",
        "    print(f\"📝 Exporting {len(papers)} papers to BibTeX...\")\n",
        "\n",
        "    bibtex_content = \"\"\n",
        "\n",
        "    for i, paper in enumerate(papers, 1):\n",
        "        # Create BibTeX entry\n",
        "        entry_type = \"article\" if paper['venue_type'] == 'Journal' else \"inproceedings\"\n",
        "        entry_key = f\"paper{i}_{paper['publication_date'].replace('-', '')}\"\n",
        "\n",
        "        bibtex_content += f\"@{entry_type}{{{entry_key},\\n\"\n",
        "        bibtex_content += f\"  title = {{{paper['title']}}},\\n\"\n",
        "        bibtex_content += f\"  author = {{{' and '.join(paper['authors'])}}},\\n\"\n",
        "\n",
        "        if paper['venue_type'] == 'Journal':\n",
        "            bibtex_content += f\"  journal = {{{paper['venue']}}},\\n\"\n",
        "        else:\n",
        "            bibtex_content += f\"  booktitle = {{{paper['venue']}}},\\n\"\n",
        "\n",
        "        bibtex_content += f\"  year = {{{paper['publication_date'][:4]}}},\\n\"\n",
        "\n",
        "        if paper.get('doi'):\n",
        "            bibtex_content += f\"  doi = {{{paper['doi']}}},\\n\"\n",
        "\n",
        "        bibtex_content += f\"  note = {{Relevance: {paper['relevance_score']:.2f}}}\\n\"\n",
        "        bibtex_content += \"}\\n\\n\"\n",
        "\n",
        "    # Save to file\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        f.write(bibtex_content)\n",
        "\n",
        "    print(f\"✅ BibTeX file saved as: {filename}\")\n",
        "\n",
        "def export_to_csv(papers, filename=\"anshul_recent_papers.csv\"):\n",
        "    \"\"\"Export papers to CSV format\"\"\"\n",
        "\n",
        "    print(f\"📊 Exporting {len(papers)} papers to CSV...\")\n",
        "\n",
        "    import csv\n",
        "\n",
        "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['title', 'authors', 'venue', 'venue_type', 'publication_date', 'relevance_score', 'doi', 'abstract']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "        writer.writeheader()\n",
        "        for paper in papers:\n",
        "            writer.writerow({\n",
        "                'title': paper['title'],\n",
        "                'authors': '; '.join(paper['authors']),\n",
        "                'venue': paper['venue'],\n",
        "                'venue_type': paper['venue_type'],\n",
        "                'publication_date': paper['publication_date'],\n",
        "                'relevance_score': paper['relevance_score'],\n",
        "                'doi': paper.get('doi', ''),\n",
        "                'abstract': paper.get('abstract', '')[:200] + '...' if len(paper.get('abstract', '')) > 200 else paper.get('abstract', '')\n",
        "            })\n",
        "\n",
        "    print(f\"✅ CSV file saved as: {filename}\")\n",
        "\n",
        "def create_research_dashboard_data():\n",
        "    \"\"\"Create data for research dashboard\"\"\"\n",
        "\n",
        "    print(\"📊 Creating research dashboard data...\")\n",
        "\n",
        "    dashboard_data = {\n",
        "        'researcher_profile': {\n",
        "            'name': your_profile['name'],\n",
        "            'orcid_id': your_profile['orcid_id'],\n",
        "            'total_publications': len(your_profile['publications']),\n",
        "            'journal_papers': len(your_profile['journal_papers']),\n",
        "            'conference_papers': len(your_profile['conference_papers']),\n",
        "            'research_keywords': your_profile['keywords'],\n",
        "            'research_interests': your_profile.get('interests', [])\n",
        "        },\n",
        "        'recent_papers_summary': {\n",
        "            'total_found': len(recent_papers),\n",
        "            'highly_relevant': len([p for p in recent_papers if p['relevance_score'] > 0.7]),\n",
        "            'by_venue_type': {\n",
        "                'Journal': len([p for p in recent_papers if p['venue_type'] == 'Journal']),\n",
        "                'Conference': len([p for p in recent_papers if p['venue_type'] == 'Conference']),\n",
        "                'Preprint': len([p for p in recent_papers if p['venue_type'] == 'Preprint'])\n",
        "            },\n",
        "            'top_venues': {}\n",
        "        },\n",
        "        'research_trends': {\n",
        "            'emerging_keywords': [],\n",
        "            'collaboration_opportunities': [],\n",
        "            'research_gaps': []\n",
        "        },\n",
        "        'recommendations': {\n",
        "            'papers_to_read': [p for p in recent_papers if p['relevance_score'] > 0.8][:5],\n",
        "            'conferences_to_attend': [],\n",
        "            'researchers_to_follow': []\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Save dashboard data\n",
        "    with open('research_dashboard_data.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(dashboard_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(\"✅ Dashboard data saved as: research_dashboard_data.json\")\n",
        "\n",
        "    return dashboard_data\n",
        "\n",
        "def setup_alert_system(keywords, relevance_threshold=0.7):\n",
        "    \"\"\"Setup alert system for new papers\"\"\"\n",
        "\n",
        "    print(\"🔔 Setting up research paper alert system...\")\n",
        "\n",
        "    alert_config = {\n",
        "        'researcher_name': your_profile['name'],\n",
        "        'orcid_id': your_profile['orcid_id'],\n",
        "        'alert_keywords': keywords,\n",
        "        'relevance_threshold': relevance_threshold,\n",
        "        'sources': ['arXiv', 'IEEE Xplore', 'ACM Digital Library'],\n",
        "        'frequency': 'weekly',\n",
        "        'last_check': datetime.now().strftime('%Y-%m-%d'),\n",
        "        'email_alerts': True,\n",
        "        'max_papers_per_alert': 10\n",
        "    }\n",
        "\n",
        "    with open('alert_config.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(alert_config, f, indent=2)\n",
        "\n",
        "    print(\"✅ Alert system configured!\")\n",
        "    print(f\"📧 Will monitor {len(keywords)} keywords\")\n",
        "    print(f\"🎯 Relevance threshold: {relevance_threshold}\")\n",
        "    print(\"⏰ Check frequency: weekly\")\n",
        "\n",
        "# Run export functions\n",
        "print(\"🚀 Running export functions...\")\n",
        "\n",
        "# Export to different formats\n",
        "export_to_bibtex(recent_papers[:20])  # Export top 20 papers\n",
        "export_to_csv(recent_papers)\n",
        "dashboard_data = create_research_dashboard_data()\n",
        "setup_alert_system(your_profile['keywords'][:10])\n",
        "\n",
        "print(\"\\n✅ All export functions completed!\")\n",
        "print(\"📁 Files created:\")\n",
        "print(\"  • anshul_recent_papers.bib\")\n",
        "print(\"  • anshul_recent_papers.csv\")\n",
        "print(\"  • anshul_research_report.md\")\n",
        "print(\"  • research_dashboard_data.json\")\n",
        "print(\"  • alert_config.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-29AAYtzauv"
      },
      "source": [
        "===== CELL: System Status and Next Steps ====="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qo_JEVVxzkJv",
        "outputId": "ddb41ffc-d2f4-42ca-9fbc-cc815f1a464d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "🎊 PERSONALIZED RESEARCH DISCOVERY SYSTEM - COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "📊 SYSTEM SUMMARY:\n",
            "├── 👤 Researcher: Anshul Pandey\n",
            "├── 🆔 ORCID ID: 0000-0001-7911-3451\n",
            "├── 📚 Your Publications: 29 (16 journals, 13 conferences)\n",
            "├── 🔍 Recent Papers Found: 32\n",
            "├── 🎯 Highly Relevant: 25\n",
            "├── 🔑 Research Keywords: 13\n",
            "├── 💬 RAG Vector Database: 83 vectors\n",
            "└── 📄 Export Files: 5 files generated\n",
            "\n",
            "🚀 READY-TO-USE FUNCTIONS:\n",
            "├── ask_anshul_assistant('your question')\n",
            "├── query_anshul_research_assistant()\n",
            "├── fetch_recent_papers_for_anshul()\n",
            "├── export_to_bibtex()\n",
            "├── export_to_csv()\n",
            "└── create_research_dashboard_data()\n",
            "\n",
            "🎯 IMMEDIATE NEXT STEPS:\n",
            "1. Try the sample queries above\n",
            "2. Review your research report (anshul_research_report.md)\n",
            "3. Check exported BibTeX file for relevant papers\n",
            "4. Set up weekly automated runs\n",
            "5. Integrate with your reference manager\n",
            "\n",
            "💡 ADVANCED FEATURES:\n",
            "• Personalized relevance scoring based on your publications\n",
            "• Multi-format export (BibTeX, CSV, JSON)\n",
            "• Research trend analysis\n",
            "• Collaboration opportunity identification\n",
            "• Alert system for new papers\n",
            "\n",
            "🔄 MAINTENANCE:\n",
            "• Run weekly to stay updated\n",
            "• Adjust relevance thresholds as needed\n",
            "• Add new data sources\n",
            "• Update research keywords based on new interests\n",
            "\n",
            "✅ SYSTEM STATUS: FULLY OPERATIONAL AND READY FOR USE!\n",
            "\n",
            "\n",
            "🎉 Congratulations! Your personalized research discovery system is ready!\n",
            "🚀 Start exploring with: ask_anshul_assistant('What should I research next?')\n",
            "\n",
            "🧪 FINAL SYSTEM TEST:\n",
            "Query: Based on my research profile and recent papers, what are the top 3 research directions I should focus on in the next year?\n",
            "--------------------------------------------------\n",
            "🤔 Processing your query: Based on my research profile and recent papers, what are the top 3 research directions I should focus on in the next year?\n",
            "\n",
            "Based on your research profile in cognitive radio, channel estimation, security, here's what I found:\n",
            "\n",
            "**Query:** Based on my research profile and recent papers, what are the top 3 research directions I should focus on in the next year?\n",
            "\n",
            "**Your Research Focus:** cognitive radio, channel estimation, security, MIMO, cooperative\n",
            "\n",
            "**Analysis:**\n",
            "From the available research papers and your publication history, several key points emerge:\n",
            "\n",
            "1. **Recent Developments:** The field shows active research in areas aligned with your expertise\n",
            "2. **Research Opportunities:** Multiple papers indicate emerging trends in your domains\n",
            "3. **Collaboration Potential:** Several research groups are working on complementary problems\n",
            "\n",
            "**Key Findings from Retrieved Papers:**\n",
            "---\n",
            "\n",
            "\n",
            "\n",
            "RECENT RELEVANT PAPERS IN YOUR FIELD:\n",
            "\n",
            "\n",
            "Title: How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks\n",
            "Authors: Rahul Ramachandran, Ali Garjani, Roman Bachmann, Andrei Atanov, Oğuzhan Fatih Kar, Amir Zamir\n",
            "Venue: arXiv (Preprint) (Preprint)\n",
            "Publication Date: 2025-07-02\n",
            "Relevance to Your Research: 1.00\n",
            "\n",
            "DOI/URL: arXiv:2507.01799v1\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training\n",
            "Authors: Ismail Labiad, Mathurin Videau, Matthieu Kowalski, Marc Schoenauer, Alessandro Leite, Julia Kempe, Olivier Teytaud\n",
            "Venue: arXiv (Preprint) (Preprint)\n",
            "Publication Date: 2025-07-02\n",
            "Relevance to Your Research: 1.00\n",
            "\n",
            "DOI/URL: arXiv:2507.01487v1\n",
            "\n",
            "---\n",
            "\n",
            "\n",
            "Title: A new efficient RPKI Design\n",
            "Authors:...\n",
            "\n",
            "**Recommendations:**\n",
            "- Focus on interdisciplinary approaches combining your expertise areas\n",
            "- Consider collaborative research opportunities with researchers working on similar problems\n",
            "- Stay updated with recent developments in your specific research domains\n",
            "\n",
            "**Note:** For more detailed AI-powered analysis, ensure your OpenAI API has sufficient credits.\n",
            "\n",
            "\n",
            "✅ SYSTEM TEST SUCCESSFUL!\n",
            "\n",
            "🎯 READY TO DISCOVER YOUR NEXT BREAKTHROUGH! 🚀\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🎊 PERSONALIZED RESEARCH DISCOVERY SYSTEM - COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\"\"\n",
        "📊 SYSTEM SUMMARY:\n",
        "├── 👤 Researcher: {your_profile['name']}\n",
        "├── 🆔 ORCID ID: {your_profile['orcid_id']}\n",
        "├── 📚 Your Publications: {len(your_profile['publications'])} ({len(your_profile['journal_papers'])} journals, {len(your_profile['conference_papers'])} conferences)\n",
        "├── 🔍 Recent Papers Found: {len(recent_papers)}\n",
        "├── 🎯 Highly Relevant: {len([p for p in recent_papers if p['relevance_score'] > 0.7])}\n",
        "├── 🔑 Research Keywords: {len(your_profile['keywords'])}\n",
        "├── 💬 RAG Vector Database: {db.index.ntotal} vectors\n",
        "└── 📄 Export Files: 5 files generated\n",
        "\n",
        "🚀 READY-TO-USE FUNCTIONS:\n",
        "├── ask_anshul_assistant('your question')\n",
        "├── query_anshul_research_assistant()\n",
        "├── fetch_recent_papers_for_anshul()\n",
        "├── export_to_bibtex()\n",
        "├── export_to_csv()\n",
        "└── create_research_dashboard_data()\n",
        "\n",
        "🎯 IMMEDIATE NEXT STEPS:\n",
        "1. Try the sample queries above\n",
        "2. Review your research report (anshul_research_report.md)\n",
        "3. Check exported BibTeX file for relevant papers\n",
        "4. Set up weekly automated runs\n",
        "5. Integrate with your reference manager\n",
        "\n",
        "💡 ADVANCED FEATURES:\n",
        "• Personalized relevance scoring based on your publications\n",
        "• Multi-format export (BibTeX, CSV, JSON)\n",
        "• Research trend analysis\n",
        "• Collaboration opportunity identification\n",
        "• Alert system for new papers\n",
        "\n",
        "🔄 MAINTENANCE:\n",
        "• Run weekly to stay updated\n",
        "• Adjust relevance thresholds as needed\n",
        "• Add new data sources\n",
        "• Update research keywords based on new interests\n",
        "\n",
        "✅ SYSTEM STATUS: FULLY OPERATIONAL AND READY FOR USE!\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n🎉 Congratulations! Your personalized research discovery system is ready!\")\n",
        "print(\"🚀 Start exploring with: ask_anshul_assistant('What should I research next?')\")\n",
        "\n",
        "# Test the complete system one final time\n",
        "print(\"\\n🧪 FINAL SYSTEM TEST:\")\n",
        "final_test_query = \"Based on my research profile and recent papers, what are the top 3 research directions I should focus on in the next year?\"\n",
        "print(f\"Query: {final_test_query}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "try:\n",
        "    final_response = ask_anshul_assistant(final_test_query)\n",
        "    print(final_response)\n",
        "    print(\"\\n✅ SYSTEM TEST SUCCESSFUL!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ System test failed: {e}\")\n",
        "    print(\"Please check your OpenAI API key and internet connection.\")\n",
        "\n",
        "print(\"\\n🎯 READY TO DISCOVER YOUR NEXT BREAKTHROUGH! 🚀\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APaySaLJ1bUp"
      },
      "source": [
        "Final CELL: Download all files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "WdLkTjC-1UFw",
        "outputId": "d913f929-6211-4df5-9522-82681aa97e3f"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_9e4e7087-0ecb-4d66-a980-931952b45faa\", \"anshul_research_report.md\", 5781)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Downloaded: anshul_research_report.md\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_b2684825-6922-4918-8ac9-36a317a1f299\", \"anshul_research_corpus.txt\", 56096)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Downloaded: anshul_research_corpus.txt\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_80c4a380-56a0-4b54-bf9e-42325b9b73ce\", \"anshul_recent_papers.bib\", 6861)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Downloaded: anshul_recent_papers.bib\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_4a4371b4-b548-4ea5-acc0-b83da446e7cf\", \"anshul_recent_papers.csv\", 13764)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Downloaded: anshul_recent_papers.csv\n"
          ]
        }
      ],
      "source": [
        "# Download all generated files\n",
        "from google.colab import files\n",
        "\n",
        "files_to_download = [\n",
        "    'anshul_research_report.md',\n",
        "    'anshul_research_corpus.txt',\n",
        "    'anshul_recent_papers.bib',\n",
        "    'anshul_recent_papers.csv'\n",
        "]\n",
        "\n",
        "for filename in files_to_download:\n",
        "    try:\n",
        "        files.download(filename)\n",
        "        print(f\"✅ Downloaded: {filename}\")\n",
        "    except:\n",
        "        print(f\"❌ File not found: {filename}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
